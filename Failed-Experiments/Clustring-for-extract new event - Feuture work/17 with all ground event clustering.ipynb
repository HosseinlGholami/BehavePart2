{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the name of GOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def color_map_color(value, cmap_name='coolwarm', vmin=0, vmax=10):\n",
    "    # norm = plt.Normalize(vmin, vmax)\n",
    "    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = cm.get_cmap(cmap_name)  # PiYG\n",
    "    rgb = cmap(norm(abs(value)))[:3]  # will return rgba, we take only first 3 so we get rgb\n",
    "    color = matplotlib.colors.rgb2hex(rgb)\n",
    "    return color\n",
    "cl=['r','g','b','c','m','y','k']\n",
    "color=dict()\n",
    "for i,el in enumerate(cl):\n",
    "    color.update({i:el})\n",
    "#extract the labels for clutering precision its for after clustering\n",
    "def time_convertor(x):\n",
    "    s,h,m=0,0,0\n",
    "    s=round(x%60,2)\n",
    "    m=int(x/60)\n",
    "    h=int(m/60)\n",
    "    m=m%60\n",
    "    time=str(h)+':'+str(m)+':'+str(s)\n",
    "    return pd.to_datetime('1970-01-01 '+time)\n",
    "\n",
    "\n",
    "# Display figures inline in Jupyter notebook\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(15, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('16\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('16\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df1 = pd.concat([dfa, dfg], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('17\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('17\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df2 = pd.concat([dfa, dfg], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('20\\\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('20\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df3 = pd.concat([dfa, dfg], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('21\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('21\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df4 = pd.concat([dfa, dfg], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Labeled dataset on 16\n",
    "dfl=pd.read_csv('16\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "lmean=dfl.length.mean()\n",
    "lstd=dfl.length.std()\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_1=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_1.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Labeled dataset on 17\n",
    "dfl=pd.read_csv('17\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "lmean=dfl.length.mean()\n",
    "lstd=dfl.length.std()\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_2=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_2.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Labeled dataset on 20\n",
    "dfl=pd.read_csv('20\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "lmean=dfl.length.mean()\n",
    "lstd=dfl.length.std()\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_3=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_3.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Labeled dataset on 21\n",
    "dfl=pd.read_csv('17\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "lmean=dfl.length.mean()\n",
    "lstd=dfl.length.std()\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_4=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_4.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp_event_on17.txt\", \"rb\") as fp:\n",
    "    te = pickle.load(fp)\n",
    "with open(\"distance_on17.txt\", \"rb\") as fp:\n",
    "    dc = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  100.0  %   is complete on  4\n",
      "42 min has time for calculaton distant\n"
     ]
    }
   ],
   "source": [
    "#Dont RUN this part\n",
    "#clustering precision\n",
    "def eveluate_ground_distance_from_temp_eventt(df,evented_label,temp_event,Name):\n",
    "    n=0\n",
    "    k=len(temp_event)*len(evented_label)\n",
    "    labels_distance=list()\n",
    "\n",
    "    for tag,st,en in evented_label:\n",
    "        dummy=list()\n",
    "        for t_e in temp_event:\n",
    "            clear_output(wait=True)\n",
    "            n=n+1\n",
    "            print('disstance calculatoin ',round((n/k)*100,2),' %   is complete on ',Name )\n",
    "            dist,_=fastdtw(df[st:en],t_e)\n",
    "            dummy.append(dist)\n",
    "        labels_distance.append((tag,dummy))\n",
    "    return labels_distance\n",
    "\n",
    "t1=time.time()\n",
    "ld1=eveluate_ground_distance_from_temp_eventt(df1,evented_label_1,te,'1')\n",
    "\n",
    "ld2=eveluate_ground_distance_from_temp_eventt(df2,evented_label_2,te,'2')\n",
    "\n",
    "ld3=eveluate_ground_distance_from_temp_eventt(df3,evented_label_3,te,'3')\n",
    "    \n",
    "ld4=eveluate_ground_distance_from_temp_eventt(df4,evented_label_4,te,'4')\n",
    "ld=ld1+ld2+ld3+ld4\n",
    "with open(\"ld_on17.txt\", \"wb\") as fp:\n",
    "    pickle.dump(ld4, fp)\n",
    "t2=time.time()\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton distant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ld_on17.txt\", \"rb\") as fp:\n",
    "    ld = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from copy import deepcopy\n",
    "\n",
    "#plot and optimize the number of the cluster and the linkage method\n",
    "def creat_Symmetric_matrix(file):  \n",
    "    MTX=deepcopy(file)\n",
    "    for i in range(len(MTX)):\n",
    "        while len(MTX[i])!=len(MTX):\n",
    "            MTX[i].append(0)\n",
    "    #make it Symmetry from diameter\n",
    "    arr=np.array(MTX)\n",
    "    dis=np.array(MTX)\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(arr)):\n",
    "            if (i>j):\n",
    "                dis[j][i]=arr[i][j]\n",
    "    return dis\n",
    "\n",
    "def Mean(dprecision):\n",
    "    return np.mean(list(dict(dprecision).values()))\n",
    "\n",
    "def Oploter(number_of_cluster , linkage_method):\n",
    "    #calculate the precision of clustering by labeled data \n",
    "    exploratory_analysis=list()\n",
    "    for i,el in enumerate(ld):\n",
    "        midle_list=list()\n",
    "        label_tag =el[0]\n",
    "        label_distance=el[1].copy()\n",
    "        label_distance.append(0)\n",
    "        distance_matrix=deepcopy(dc)\n",
    "        distance_matrix.append(label_distance)\n",
    "        DMX=creat_Symmetric_matrix(distance_matrix)\n",
    "        Labels = AgglomerativeClustering(n_clusters=number_of_cluster, affinity='precomputed', linkage = linkage_method).fit(DMX).labels_\n",
    "\n",
    "        #extract lable  and labele it from the item we put at the end\n",
    "        for i , x in enumerate(Labels):\n",
    "            if i!=(len(Labels)-1):\n",
    "                if x==Labels[-1]:\n",
    "                    midle_list.append(i)\n",
    "        exploratory_analysis.append([label_tag,midle_list])\n",
    "    \n",
    "    actg=dict()\n",
    "    for ev,x in exploratory_analysis:\n",
    "        if ev in actg:\n",
    "            actg[ev].append(x)\n",
    "        else:\n",
    "            actg.update({ev:[x]})\n",
    "    #calculate the Probibility of being event of temp_event\n",
    "    Prob_threshold=0.1\n",
    "    precision=list()\n",
    "    for event_name in actg:\n",
    "        flat_list=list(dict.fromkeys(flatten(actg[event_name])))\n",
    "        dprecision=list()\n",
    "        for S in flat_list:\n",
    "            x=0\n",
    "            Number=len(actg[event_name])\n",
    "            for i in range(Number):\n",
    "                if S in actg[event_name][i]:\n",
    "                    x=x+1\n",
    "            Probability=x/Number\n",
    "            if Probability > Prob_threshold:\n",
    "                dprecision.append((S,Probability))\n",
    "        precision.append((event_name,len(dprecision),Mean(dprecision),dprecision))\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\hosse\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot extract more clusters than samples: 805 clusters where given for a tree with 793 leaves.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d1e13ded484b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum_cl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOploter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_cl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinkage_mth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mYa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-d725eaad0831>\u001b[0m in \u001b[0;36mOploter\u001b[1;34m(number_of_cluster, linkage_method)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mdistance_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mDMX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreat_Symmetric_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_of_cluster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffinity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precomputed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinkage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinkage_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDMX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m#extract lable  and labele it from the item we put at the end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\_agglomerative.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompute_full_tree\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             self.labels_ = _hc_cut(self.n_clusters_, self.children_,\n\u001b[1;32m--> 898\u001b[1;33m                                    self.n_leaves_)\n\u001b[0m\u001b[0;32m    899\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_hierarchical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhc_get_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\_agglomerative.py\u001b[0m in \u001b[0;36m_hc_cut\u001b[1;34m(n_clusters, children, n_leaves)\u001b[0m\n\u001b[0;32m    657\u001b[0m         raise ValueError('Cannot extract more clusters than samples: '\n\u001b[0;32m    658\u001b[0m                          \u001b[1;34m'%s clusters where given for a tree with %s leaves.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m                          % (n_clusters, n_leaves))\n\u001b[0m\u001b[0;32m    660\u001b[0m     \u001b[1;31m# In this function, we store nodes as a heap to avoid recomputing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[1;31m# the max of the nodes: the first element is always the smallest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot extract more clusters than samples: 805 clusters where given for a tree with 793 leaves."
     ]
    }
   ],
   "source": [
    "#linkage method average\n",
    "linkage_mth='average'\n",
    "Ya=list()\n",
    "t1=time.time()\n",
    "X=range(5,1100,50)\n",
    "for num_cl in X:\n",
    "    X=Oploter(num_cl,linkage_mth)\n",
    "    Ya.append(X)\n",
    "t2=time.time()\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton distant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_num=dict()\n",
    "for i in range(0,6):\n",
    "    Y_num.update({i:[x[i][1] for x in Ya]})\n",
    "fig, ax = plt.subplots()\n",
    "X=range(5,1100,50)\n",
    "for i in range(0,6):\n",
    "    ax.plot(X,Y_num[i], linestyle='-', linewidth=2,c=color[i])\n",
    "ax.legend();\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Q=dict()\n",
    "for i in range(0,6):\n",
    "    Y_Q.update({i:[x[i][2] for x in Ya]})\n",
    "fig, ax = plt.subplots()\n",
    "X=range(5,1100,50)\n",
    "for i in range(0,6):\n",
    "    ax.plot(X,Y_Q[i], linestyle='-', linewidth=2,c=color[i])\n",
    "ax.legend();\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "def end ():\n",
    "    for i in range (3):\n",
    "        frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "        duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "        winsound.Beep(frequency, duration)\n",
    "        frequency = 500  # Set Frequency To 2500 Hertz\n",
    "        duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "        winsound.Beep(frequency, duration)\n",
    "        frequency = 1000  # Set Frequency To 2500 Hertz\n",
    "        duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "        winsound.Beep(frequency, duration)\n",
    "    frequency = 1000  # Set Frequency To 2500 Hertz\n",
    "    duration = 10000  # Set Duration To 1000 ms == 1 second\n",
    "    winsound.Beep(frequency, duration)\n",
    "end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
