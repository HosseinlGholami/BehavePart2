{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the name of GOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def color_map_color(value, cmap_name='coolwarm', vmin=0, vmax=10):\n",
    "    # norm = plt.Normalize(vmin, vmax)\n",
    "    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = cm.get_cmap(cmap_name)  # PiYG\n",
    "    rgb = cmap(norm(abs(value)))[:3]  # will return rgba, we take only first 3 so we get rgb\n",
    "    color = matplotlib.colors.rgb2hex(rgb)\n",
    "    return color\n",
    "cl=['r','g','b','c','m','y','k']\n",
    "color=dict()\n",
    "for i,el in enumerate(cl):\n",
    "    color.update({i:el})\n",
    "#extract the labels for clutering precision its for after clustering\n",
    "def time_convertor(x):\n",
    "    s,h,m=0,0,0\n",
    "    s=round(x%60,2)\n",
    "    m=int(x/60)\n",
    "    h=int(m/60)\n",
    "    m=m%60\n",
    "    time=str(h)+':'+str(m)+':'+str(s)\n",
    "    return pd.to_datetime('1970-01-01 '+time)\n",
    "\n",
    "\n",
    "# Display figures inline in Jupyter notebook\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(15, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_read\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('16\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('16\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df1 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('17\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('17\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df2 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('20\\\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('20\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df3 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('21\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('21\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df4 = pd.concat([dfa, dfg], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_event_lenght=dict()\n",
    "#prepare Labeled dataset on 16\n",
    "dfl=pd.read_csv('16\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "        \n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_1=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_1.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 17\n",
    "dfl=pd.read_csv('17\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_2=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_2.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 20\n",
    "dfl=pd.read_csv('20\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_3=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_3.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 21\n",
    "dfl=pd.read_csv('21\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_4=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_4.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve1=pd.DataFrame(evented_label_1)\n",
    "eve1[3]=['evented_label_1' for x in evented_label_1]\n",
    "\n",
    "#eve2=pd.DataFrame(evented_label_2)\n",
    "#eve2[3]=['evented_label_2' for x in evented_label_2]\n",
    "\n",
    "eve3=pd.DataFrame(evented_label_3)\n",
    "eve3[3]=['evented_label_3' for x in evented_label_3]\n",
    "\n",
    "eve4=pd.DataFrame(evented_label_4)\n",
    "eve4[3]=['evented_label_4' for x in evented_label_4]\n",
    "\n",
    "evented_label=pd.concat([eve1,eve3,eve4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('curva_direita_agressiva', 225),\n",
       " ('curva_esquerda_agressiva', 225),\n",
       " ('evento_nao_agressivo', 225),\n",
       " ('troca_faixa_direita_agressiva', 125),\n",
       " ('aceleracao_agressiva', 245),\n",
       " ('freada_agressiva', 185),\n",
       " ('troca_faixa_esquerda_agressiva', 120)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=(df2.index[6]-df3.index[5]).total_seconds()\n",
    "window_list=list()\n",
    "for event in label_event_lenght:\n",
    "    window_list.append((event,round(max(label_event_lenght[event])/rate)))\n",
    "window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supervised\n",
    "window={226:['curva_direita_agressiva','curva_esquerda_agressiva','aceleracao_agressiva'],\n",
    "        126:['troca_faixa_direita_agressiva','troca_faixa_esquerda_agressiva'],\n",
    "        186:['freada_agressiva']\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"EM_tmp_on17.txt\", \"rb\") as fp:\n",
    "    temp_event = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  46.9844  %  is complete\n"
     ]
    }
   ],
   "source": [
    "#calculate tempevnt with labdeled event\n",
    "Dum=evented_label.groupby(0).size()\n",
    "n=0\n",
    "k=0\n",
    "t1=time.time()\n",
    "for L , AEV in temp_event:\n",
    "    for i in L: \n",
    "        k=k+len(AEV)*Dum[i]\n",
    "\n",
    "EVENT_DS=dict()\n",
    "for L , AEV in temp_event:\n",
    "    for eve_name in L:\n",
    "        Y=list()\n",
    "        for EV in AEV:\n",
    "            X=list()\n",
    "            for eve,dfe in evented_label.groupby(0):\n",
    "                if eve==eve_name:\n",
    "                    for el in dfe.iloc:\n",
    "                        clear_output(wait=True)\n",
    "                        n=n+1\n",
    "                        print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "                        if   el[3]=='evented_label_1':\n",
    "                            X.append(fastdtw(EV,df1[el[1]:el[2]])[0])\n",
    "                        elif el[3]=='evented_label_2':\n",
    "                            X.append(fastdtw(EV,df2[el[1]:el[2]])[0])\n",
    "                        elif el[3]=='evented_label_3':\n",
    "                            X.append(fastdtw(EV,df3[el[1]:el[2]])[0])\n",
    "                        elif el[3]=='evented_label_4':\n",
    "                            X.append(fastdtw(EV,df4[el[1]:el[2]])[0])\n",
    "            Y.append(X)\n",
    "        EVENT_DS.update({eve_name:Y})\n",
    "\n",
    "t2=time.time()\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton distant')\n",
    "\n",
    "with open(\"EM_DIS_on17ss.txt\", \"wb\") as fp:\n",
    "    pickle.dump(EVENT_DS, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"EM_DIS_on17ss.txt\", \"rb\") as fp:\n",
    "    EVENT_DS = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_DS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it mean for each event from labeld \n",
    "med=dict()\n",
    "for eve in EVENT_DS:\n",
    "    x=list()\n",
    "    for ev in EVENT_DS[eve]:\n",
    "        x.append(min(ev))\n",
    "    med.update({eve:x})\n",
    "\n",
    "#export relevent with thease two parameter\n",
    "def export_relevent_index(name,threshold=3,window=10):\n",
    "    X=med[name].copy()\n",
    "    X.sort()\n",
    "    relevent=list()\n",
    "    dfr=[X[i+1]-X[i] for i in range(len(X)-1)]\n",
    "    for i,el in enumerate(X):\n",
    "        Criterion=np.mean(dfr[i:i+window])\n",
    "        if Criterion>threshold:\n",
    "            relevent.append(el)\n",
    "        else:\n",
    "            break\n",
    "    return [med[name].index(x)for x in relevent]\n",
    "\n",
    "indexes=dict()\n",
    "for name in EVENT_DS:\n",
    "    indexes.update({name:export_relevent_index(name)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_overlap(A_start, A_end, B_start, B_end):\n",
    "    latest_start = max(A_start, B_start)\n",
    "    earliest_end = min(A_end, B_end)\n",
    "    return latest_start <= earliest_end\n",
    "\n",
    "#Done = dict.fromkeys(ini_set, 0) \n",
    "Done=list()\n",
    "for name in indexes:\n",
    "    if name in {x[0] for x in evented_label_2}:\n",
    "        for i in range(0,3):\n",
    "            if name in temp_event[i][0]:\n",
    "                for Index in indexes[name]:\n",
    "                    sta=temp_event[i][1][Index].index[0]\n",
    "                    ena =temp_event[i][1][Index].index[-1]\n",
    "                    el=[(j,x[1],x[2]) for j,x in enumerate(evented_label_2) if x[0]==name]\n",
    "                    for jj,stb,enb in el:\n",
    "                        if has_overlap(sta,ena,stb,enb):\n",
    "                            Done.append((name,jj,Index))\n",
    "print(len(Done),'event has extract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events=[x[2] for x in Done if x[0]=='troca_faixa_direita_agressiva']\n",
    "\n",
    "num=indexes['troca_faixa_direita_agressiva'].index(events[-1])\n",
    "my_pridict=indexes['troca_faixa_direita_agressiva'][0:num]\n",
    "\n",
    "accuracy=len(events)/len(my_pridict)\n",
    "print('accuracy is : ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we should cheack to in wich case we can have the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=15\n",
    "indexes=dict()\n",
    "for name in EVENT_DS:\n",
    "    indexes.update({name:export_relevent_index(name,threshold,window=10)})\n",
    "Done=list()\n",
    "for name in indexes:\n",
    "    if name in {x[0] for x in evented_label_2}:\n",
    "        for i in range(0,3):\n",
    "            if name in temp_event[i][0]:\n",
    "                for Index in indexes[name]:\n",
    "                    sta=temp_event[i][1][Index].index[0]\n",
    "                    ena =temp_event[i][1][Index].index[-1]\n",
    "                    el=[(j,x[1],x[2]) for j,x in enumerate(evented_label_2) if x[0]==name]\n",
    "                    for jj,stb,enb in el:\n",
    "                        if has_overlap(sta,ena,stb,enb):\n",
    "                            Done.append((name,jj,Index))\n",
    "\n",
    "print('threshold is : ',threshold)\n",
    "name='aceleracao_agressiva'\n",
    "my_pridict=indexes[name]\n",
    "my_pridict.sort()\n",
    "true_predict=[x[2] for x in Done if x[0]==name]\n",
    "true_predict.sort()\n",
    "print(name)\n",
    "\n",
    "if len(my_pridict) ==0:\n",
    "    acc=0\n",
    "else:\n",
    "    acc=len(true_predict)/len(my_pridict)\n",
    "\n",
    "print('accuracy:',acc,'\\n my predict    ',my_pridict,'\\n true predict :',true_predict)\n",
    "\n",
    "real_index_events=list({x[1] for x in Done if x[0]==name})\n",
    "real_labeled_index_event=[i for i,x in enumerate(evented_label_2) if x[0]==name]\n",
    "\n",
    "print(' comprehensivity accuracy: ',len(real_index_events)/len(real_labeled_index_event),'\\n predicted events:',real_index_events,'\\n real events:     ',real_labeled_index_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=10\n",
    "indexes=dict()\n",
    "for name in EVENT_DS:\n",
    "    indexes.update({name:export_relevent_index(name,threshold,window=10)})\n",
    "Done=list()\n",
    "for name in indexes:\n",
    "    if name in {x[0] for x in evented_label_2}:\n",
    "        for i in range(0,3):\n",
    "            if name in temp_event[i][0]:\n",
    "                for Index in indexes[name]:\n",
    "                    sta=temp_event[i][1][Index].index[0]\n",
    "                    ena =temp_event[i][1][Index].index[-1]\n",
    "                    el=[(j,x[1],x[2]) for j,x in enumerate(evented_label_2) if x[0]==name]\n",
    "                    for jj,stb,enb in el:\n",
    "                        if has_overlap(sta,ena,stb,enb):\n",
    "                            Done.append((name,jj,Index))\n",
    "\n",
    "print('threshold is : ',threshold)\n",
    "name='freada_agressiva'\n",
    "my_pridict=indexes[name]\n",
    "my_pridict.sort()\n",
    "true_predict=[x[2] for x in Done if x[0]==name]\n",
    "true_predict.sort()\n",
    "print(name)\n",
    "\n",
    "if len(my_pridict) ==0:\n",
    "    acc=0\n",
    "else:\n",
    "    acc=len(true_predict)/len(my_pridict)\n",
    "\n",
    "print('accuracy:',acc,'\\n my predict    ',my_pridict,'\\n true predict :',true_predict)\n",
    "\n",
    "real_index_events=list({x[1] for x in Done if x[0]==name})\n",
    "real_labeled_index_event=[i for i,x in enumerate(evented_label_2) if x[0]==name]\n",
    "\n",
    "print(' comprehensivity accuracy: ',len(real_index_events)/len(real_labeled_index_event),'\\n predicted events:',real_index_events,'\\n real events:     ',real_labeled_index_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=20\n",
    "indexes=dict()\n",
    "for name in EVENT_DS:\n",
    "    indexes.update({name:export_relevent_index(name,threshold,window=10)})\n",
    "Done=list()\n",
    "for name in indexes:\n",
    "    if name in {x[0] for x in evented_label_2}:\n",
    "        for i in range(0,3):\n",
    "            if name in temp_event[i][0]:\n",
    "                for Index in indexes[name]:\n",
    "                    sta=temp_event[i][1][Index].index[0]\n",
    "                    ena =temp_event[i][1][Index].index[-1]\n",
    "                    el=[(j,x[1],x[2]) for j,x in enumerate(evented_label_2) if x[0]==name]\n",
    "                    for jj,stb,enb in el:\n",
    "                        if has_overlap(sta,ena,stb,enb):\n",
    "                            Done.append((name,jj,Index))\n",
    "\n",
    "print('threshold is : ',threshold)\n",
    "name='troca_faixa_direita_agressiva'\n",
    "my_pridict=indexes[name]\n",
    "my_pridict.sort()\n",
    "true_predict=[x[2] for x in Done if x[0]==name]\n",
    "true_predict.sort()\n",
    "print(name)\n",
    "\n",
    "if len(my_pridict) ==0:\n",
    "    acc=0\n",
    "else:\n",
    "    acc=len(true_predict)/len(my_pridict)\n",
    "\n",
    "print('accuracy:',acc,'\\n my predict    ',my_pridict,'\\n true predict :',true_predict)\n",
    "\n",
    "real_index_events=list({x[1] for x in Done if x[0]==name})\n",
    "real_labeled_index_event=[i for i,x in enumerate(evented_label_2) if x[0]==name]\n",
    "\n",
    "print(' comprehensivity accuracy: ',len(real_index_events)/len(real_labeled_index_event),'\\n predicted events:',real_index_events,'\\n real events:     ',real_labeled_index_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
