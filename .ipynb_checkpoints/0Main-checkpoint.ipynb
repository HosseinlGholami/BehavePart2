{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the name of god"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def color_map_color(value, cmap_name='coolwarm', vmin=0, vmax=10):\n",
    "    # norm = plt.Normalize(vmin, vmax)\n",
    "    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = cm.get_cmap(cmap_name)  # PiYG\n",
    "    rgb = cmap(norm(abs(value)))[:3]  # will return rgba, we take only first 3 so we get rgb\n",
    "    color = matplotlib.colors.rgb2hex(rgb)\n",
    "    return color\n",
    "cl=['r','g','b','c','m','y','k']\n",
    "color=dict()\n",
    "for i,el in enumerate(cl):\n",
    "    color.update({i:el})\n",
    "#extract the labels for clutering precision its for after clustering\n",
    "def time_convertor(x):\n",
    "    s,h,m=0,0,0\n",
    "    s=round(x%60,2)\n",
    "    m=int(x/60)\n",
    "    h=int(m/60)\n",
    "    m=m%60\n",
    "    time=str(h)+':'+str(m)+':'+str(s)\n",
    "    return pd.to_datetime('1970-01-01 '+time)\n",
    "\n",
    "\n",
    "# Display figures inline in Jupyter notebook\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(15, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_read\n",
    "def read_data(number):\n",
    "    #prepare Dataset gyroscope\n",
    "    dfg=pd.read_csv(f'{number}\\\\giroscopio_terra.csv')\n",
    "    dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "    dm=dfg['ts']\n",
    "    dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "    dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "    #prepare Dataset accelarator\n",
    "    dfa=pd.read_csv(f'{number}\\\\acelerometro_terra.csv')\n",
    "    dfa['ts']=dm\n",
    "    dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "    dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "    dfg['g-x']=dfg.apply(lambda x:(x[0]-min(dfg['g-x']))/(max(dfg['g-x'])-min(dfg['g-x'])),axis=1)\n",
    "    dfg['g-y']=dfg.apply(lambda x:(x[1]-min(dfg['g-y']))/(max(dfg['g-y'])-min(dfg['g-y'])),axis=1)\n",
    "    dfg['g-z']=dfg.apply(lambda x:(x[2]-min(dfg['g-z']))/(max(dfg['g-z'])-min(dfg['g-z'])),axis=1)\n",
    "    dfa['a-x']=dfa.apply(lambda x:(x[0]-min(dfa['a-x']))/(max(dfa['a-x'])-min(dfa['a-x'])),axis=1)\n",
    "    dfa['a-y']=dfa.apply(lambda x:(x[1]-min(dfa['a-y']))/(max(dfa['a-y'])-min(dfa['a-y'])),axis=1)\n",
    "    dfa['a-z']=dfa.apply(lambda x:(x[2]-min(dfa['a-z']))/(max(dfa['a-z'])-min(dfa['a-z'])),axis=1)\n",
    "    return pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "dfRaw=list()\n",
    "for num in [16,17,20,21]:\n",
    "    dfRaw.append((num,read_data(num)))\n",
    "with open(\"normalized_data.txt\", \"wb\") as fp:\n",
    "    pickle.dump(dfRaw, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"normalized_data.txt\", \"rb\") as fp:\n",
    "        dfRaw = pickle.load(fp)\n",
    "        \n",
    "def get_label(number,df):\n",
    "    label_event_lenght=dict()\n",
    "    df=pd.read_csv(f'{number}\\\\groundTruth.csv')\n",
    "    df['length']=df.en-df.st\n",
    "    for event , dft in df.groupby('evento'):\n",
    "        if (event in label_event_lenght):\n",
    "            label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "        else:\n",
    "            label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "    df['st_time']=df.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "    df['en_time']=df.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "    df=df.drop('st',1).drop('en',1).drop('length',1)\n",
    "    evented_label=list()\n",
    "    for i in range(len(df)):\n",
    "        evented_label.append((df.iloc[i][0],df.iloc[i][1],df.iloc[i][2]))\n",
    "    eve=pd.DataFrame(evented_label)\n",
    "    eve[3]=[f'evented_label_{number}' for x in evented_label]\n",
    "    return eve\n",
    "Ev=[get_label(dfRaw[x][0],dfRaw[x][1]) for x in range(len(dfRaw))]\n",
    "evented_label_All=pd.concat(Ev).reset_index().drop('index',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate is :0.02\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aceleracao_agressiva</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curva_direita_agressiva</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curva_esquerda_agressiva</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evento_nao_agressivo</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freada_agressiva</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troca_faixa_direita_agressiva</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troca_faixa_esquerda_agressiva</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  1\n",
       "0                                  \n",
       "aceleracao_agressiva            245\n",
       "curva_direita_agressiva         225\n",
       "curva_esquerda_agressiva        225\n",
       "evento_nao_agressivo            225\n",
       "freada_agressiva                185\n",
       "troca_faixa_direita_agressiva   125\n",
       "troca_faixa_esquerda_agressiva  120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=(dfRaw[0][1].index[11]-dfRaw[0][1].index[10]).total_seconds()\n",
    "\n",
    "print(f\"rate is :{rate}\")\n",
    "pd.DataFrame([(x[0],round(((x[2]-x[1]).total_seconds())/rate)) for x in evented_label_All.iloc]).groupby(0).agg({1:\"max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supervised\n",
    "window={226:['curva_direita_agressiva','curva_esquerda_agressiva','aceleracao_agressiva'],\n",
    "        126:['troca_faixa_direita_agressiva','troca_faixa_esquerda_agressiva'],\n",
    "        186:['freada_agressiva']\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction  1.0  % of  3  is complete\n"
     ]
    }
   ],
   "source": [
    "#Dont RUN this part\n",
    "#we should optimize M\n",
    "#lengh of random event\n",
    "import random\n",
    "random.seed(123)\n",
    "def TempEvent_genarator(df,L,i):\n",
    "    temp_event=list()\n",
    "    pointer=0\n",
    "    stop=False\n",
    "    #go on timeserise for event extraction\n",
    "    while stop!=True:\n",
    "        M=round(random.gauss(0.5,0.5)*L/2)\n",
    "        clear_output(wait=True)\n",
    "        pointer=pointer + M\n",
    "        l_min=pointer-int(L/2)\n",
    "        l_max=pointer+int(L/2)\n",
    "        if l_max<0:\n",
    "            l_max=L/2\n",
    "        if (l_min<0):\n",
    "            l_min=0\n",
    "        if (l_max>len(df)):\n",
    "            l_max=len(df)\n",
    "            stop=True\n",
    "        print('extraction ',l_max/len(df),' % of ',i,' is complete')\n",
    "        temp_event.append(df[int(l_min):int(l_max)])\n",
    "    return temp_event\n",
    "\n",
    "temp_event=list()\n",
    "for l,DF in enumerate([x[1] for x in dfRaw]):\n",
    "    te=list()\n",
    "    for i,lw in enumerate(window):\n",
    "        te.append((window[lw],TempEvent_genarator(DF,lw,i+1)))\n",
    "    temp_event.append(te)\n",
    "\n",
    "with open(\"temp_event_new.txt\", \"wb\") as fp:\n",
    "    pickle.dump(temp_event, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp_event_new.txt\", \"rb\") as fp:\n",
    "    temp_event = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_overlap(A_start, A_end, B_start, B_end):\n",
    "    latest_start = max(A_start, B_start)\n",
    "    earliest_end = min(A_end, B_end)\n",
    "    return latest_start <= earliest_end\n",
    "\n",
    "def export_labels(tempevent,evented_label):\n",
    "    EvL=pd.DataFrame(evented_label)\n",
    "    Labels={\n",
    "          226:[],\n",
    "          126:[],\n",
    "          186:[],\n",
    "           }\n",
    "    for i,wind in enumerate(Labels):\n",
    "        label=['NAG' for x in tempevent[i][1]]\n",
    "        for name in tempevent[i][0]:\n",
    "            el=[(x[1],x[2]) for x in EvL.iloc if x[0]==name]\n",
    "            for j,te in enumerate(tempevent[i][1]):\n",
    "                    sta =te.index[0]\n",
    "                    ena =te.index[-1]\n",
    "                    for stb,enb in el:\n",
    "                        if has_overlap(sta,ena,stb,enb):\n",
    "                            label[j]=name\n",
    "        Labels[wind]=label\n",
    "    return Labels\n",
    "\n",
    "\n",
    "Data={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "for i,temp in enumerate(temp_event):\n",
    "    TempEv={\n",
    "              226:[ x for x in temp_event[i][0][1] ],\n",
    "              126:[ x for x in temp_event[i][1][1] ],\n",
    "              186:[ x for x in temp_event[i][2][1] ],\n",
    "               }\n",
    "    Label=export_labels(temp_event[i],Ev[i])\n",
    "    #merge together\n",
    "    for wind in Data:\n",
    "        for j in range(len(TempEv[wind])):\n",
    "            Data[wind].append((Label[wind][j],TempEv[wind][j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('curva_direita_agressiva',\n",
       "                               a-x       a-y       a-z       g-x       g-y  \\\n",
       " ts                                                                          \n",
       " 1970-01-01 00:00:16.128  0.446304  0.520560  0.347449  0.615442  0.645021   \n",
       " 1970-01-01 00:00:16.148  0.434181  0.483999  0.389135  0.564097  0.721907   \n",
       " 1970-01-01 00:00:16.167  0.471788  0.504943  0.373568  0.534471  0.734305   \n",
       " 1970-01-01 00:00:16.187  0.506847  0.445671  0.321785  0.541191  0.697635   \n",
       " 1970-01-01 00:00:16.206  0.521793  0.464176  0.344837  0.547865  0.699825   \n",
       " ...                           ...       ...       ...       ...       ...   \n",
       " 1970-01-01 00:00:20.467  0.659197  0.434280  0.417008  0.606136  0.645506   \n",
       " 1970-01-01 00:00:20.487  0.660487  0.420436  0.433386  0.578697  0.631945   \n",
       " 1970-01-01 00:00:20.507  0.645925  0.408618  0.390486  0.532939  0.635908   \n",
       " 1970-01-01 00:00:20.526  0.659613  0.398597  0.364618  0.591754  0.646227   \n",
       " 1970-01-01 00:00:20.546  0.661838  0.512808  0.409471  0.633383  0.653409   \n",
       " \n",
       "                               g-z  \n",
       " ts                                 \n",
       " 1970-01-01 00:00:16.128  0.548093  \n",
       " 1970-01-01 00:00:16.148  0.521586  \n",
       " 1970-01-01 00:00:16.167  0.515252  \n",
       " 1970-01-01 00:00:16.187  0.530703  \n",
       " 1970-01-01 00:00:16.206  0.533866  \n",
       " ...                           ...  \n",
       " 1970-01-01 00:00:20.467  0.358319  \n",
       " 1970-01-01 00:00:20.487  0.357029  \n",
       " 1970-01-01 00:00:20.507  0.335985  \n",
       " 1970-01-01 00:00:20.526  0.325821  \n",
       " 1970-01-01 00:00:20.546  0.354012  \n",
       " \n",
       " [226 rows x 6 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[226][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  100.0  %  is complete\n",
      "236 min has time for calculaton distant\n"
     ]
    }
   ],
   "source": [
    "#dont run this part\n",
    "#calculate dist of Data from labdeled event\n",
    "t1=time.time()\n",
    "\n",
    "k,n=0,0\n",
    "num_event=dict(evented_label_All.groupby(0).size())\n",
    "for lenght in window:\n",
    "    for name in window[lenght]:\n",
    "        k=k+len(Data[lenght])*num_event[name]\n",
    "\n",
    "Data_DS={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wind in Data:\n",
    "    for label,event in Data[wind]:\n",
    "         #---------for each Data-distance from events----------\n",
    "        Y=list()\n",
    "        for from_event,dfe in evented_label_All.groupby(0):\n",
    "            if from_event in window[wind]:\n",
    "                X=list()\n",
    "                #____for each event_distance from each label_____\n",
    "                for el in dfe.iloc:\n",
    "                    clear_output(wait=True)\n",
    "                    n=n+1\n",
    "                    print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "                    if   el[3]=='evented_label_16':\n",
    "                        X.append(fastdtw(event,dfRaw[0][1][el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_17':\n",
    "                        X.append(fastdtw(event,dfRaw[1][1][el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_20':\n",
    "                        X.append(fastdtw(event,dfRaw[2][1][el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_21':\n",
    "                        X.append(fastdtw(event,dfRaw[3][1][el[1]:el[2]])[0])\n",
    "                #_________________________________________________\n",
    "                Y.append((from_event,X))\n",
    "        Data_DS[wind].append((label,Y))\n",
    "        #------------------------------------------------------\n",
    "\n",
    "t2=time.time()\n",
    "with open(\"Disstance_new.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Data_DS, fp)\n",
    "\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton distant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Disstance_new.txt\", \"rb\") as fp:\n",
    "    Data_DS = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('curva_direita_agressiva',\n",
       " [('aceleracao_agressiva',\n",
       "   [193.8620002602106,\n",
       "    200.17547949120848,\n",
       "    208.91120743828353,\n",
       "    189.37607467176016,\n",
       "    213.60764710549316,\n",
       "    202.77267706948095,\n",
       "    185.6126143216225,\n",
       "    200.01908361157115,\n",
       "    178.42086859902574,\n",
       "    180.43725536978405,\n",
       "    176.42141269917352,\n",
       "    177.88419755668076]),\n",
       "  ('curva_direita_agressiva',\n",
       "   [156.34105060412503,\n",
       "    141.33030286342387,\n",
       "    157.72209504056482,\n",
       "    151.77325656773988,\n",
       "    142.3189918197604,\n",
       "    204.68554013645368,\n",
       "    178.9020535176522,\n",
       "    189.28536854369844,\n",
       "    196.31336530605842,\n",
       "    204.21835919852492,\n",
       "    212.84106755762454]),\n",
       "  ('curva_esquerda_agressiva',\n",
       "   [138.2423976073504,\n",
       "    146.80978500773287,\n",
       "    137.36526112930852,\n",
       "    142.16597188457482,\n",
       "    138.12894374355054,\n",
       "    158.69089462381504,\n",
       "    161.21642134819285,\n",
       "    188.23311760134447,\n",
       "    177.4584420124825,\n",
       "    159.74073625274292,\n",
       "    163.21336986457183])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_DS[226][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataset for labeling\n",
    "TrainData=dict()\n",
    "for win in Data_DS:\n",
    "    x=Data_DS[win]\n",
    "    dumy_list=list()\n",
    "    for events in x:\n",
    "        dumy_dict=dict()\n",
    "        dumy_dict.update({'label':events[0]})\n",
    "        for name , event in events[1]:\n",
    "            for tag,number in enumerate(event):\n",
    "                dumy_dict.update({name+str(tag):number})\n",
    "        dumy_list.append(dumy_dict)\n",
    "    TrainData.update({win:pd.DataFrame(dumy_list)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>aceleracao_agressiva0</th>\n",
       "      <th>aceleracao_agressiva1</th>\n",
       "      <th>aceleracao_agressiva2</th>\n",
       "      <th>aceleracao_agressiva3</th>\n",
       "      <th>aceleracao_agressiva4</th>\n",
       "      <th>aceleracao_agressiva5</th>\n",
       "      <th>aceleracao_agressiva6</th>\n",
       "      <th>aceleracao_agressiva7</th>\n",
       "      <th>aceleracao_agressiva8</th>\n",
       "      <th>...</th>\n",
       "      <th>curva_esquerda_agressiva1</th>\n",
       "      <th>curva_esquerda_agressiva2</th>\n",
       "      <th>curva_esquerda_agressiva3</th>\n",
       "      <th>curva_esquerda_agressiva4</th>\n",
       "      <th>curva_esquerda_agressiva5</th>\n",
       "      <th>curva_esquerda_agressiva6</th>\n",
       "      <th>curva_esquerda_agressiva7</th>\n",
       "      <th>curva_esquerda_agressiva8</th>\n",
       "      <th>curva_esquerda_agressiva9</th>\n",
       "      <th>curva_esquerda_agressiva10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAG</td>\n",
       "      <td>156.195372</td>\n",
       "      <td>164.150006</td>\n",
       "      <td>187.128103</td>\n",
       "      <td>168.341293</td>\n",
       "      <td>210.468254</td>\n",
       "      <td>196.321367</td>\n",
       "      <td>177.595807</td>\n",
       "      <td>214.772692</td>\n",
       "      <td>166.894221</td>\n",
       "      <td>...</td>\n",
       "      <td>134.648802</td>\n",
       "      <td>131.349655</td>\n",
       "      <td>127.787261</td>\n",
       "      <td>125.194055</td>\n",
       "      <td>136.839273</td>\n",
       "      <td>121.556602</td>\n",
       "      <td>172.023376</td>\n",
       "      <td>172.619455</td>\n",
       "      <td>133.983289</td>\n",
       "      <td>120.291350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NAG</td>\n",
       "      <td>179.146723</td>\n",
       "      <td>189.445860</td>\n",
       "      <td>197.624226</td>\n",
       "      <td>179.174447</td>\n",
       "      <td>208.437603</td>\n",
       "      <td>195.636896</td>\n",
       "      <td>195.555334</td>\n",
       "      <td>213.071510</td>\n",
       "      <td>184.495338</td>\n",
       "      <td>...</td>\n",
       "      <td>140.005523</td>\n",
       "      <td>130.059800</td>\n",
       "      <td>128.958115</td>\n",
       "      <td>127.738862</td>\n",
       "      <td>148.062329</td>\n",
       "      <td>139.819652</td>\n",
       "      <td>184.756366</td>\n",
       "      <td>174.633300</td>\n",
       "      <td>151.950375</td>\n",
       "      <td>139.542378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAG</td>\n",
       "      <td>188.202503</td>\n",
       "      <td>197.142536</td>\n",
       "      <td>204.851447</td>\n",
       "      <td>183.723426</td>\n",
       "      <td>208.943985</td>\n",
       "      <td>195.507899</td>\n",
       "      <td>191.363939</td>\n",
       "      <td>208.260254</td>\n",
       "      <td>181.370713</td>\n",
       "      <td>...</td>\n",
       "      <td>146.358798</td>\n",
       "      <td>136.656233</td>\n",
       "      <td>132.964335</td>\n",
       "      <td>133.870663</td>\n",
       "      <td>145.985343</td>\n",
       "      <td>148.594318</td>\n",
       "      <td>190.612853</td>\n",
       "      <td>176.485091</td>\n",
       "      <td>144.656271</td>\n",
       "      <td>145.430741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NAG</td>\n",
       "      <td>189.640675</td>\n",
       "      <td>195.403324</td>\n",
       "      <td>206.805417</td>\n",
       "      <td>190.431027</td>\n",
       "      <td>215.821046</td>\n",
       "      <td>202.883993</td>\n",
       "      <td>190.642412</td>\n",
       "      <td>207.585205</td>\n",
       "      <td>180.842636</td>\n",
       "      <td>...</td>\n",
       "      <td>140.476681</td>\n",
       "      <td>137.316624</td>\n",
       "      <td>131.471869</td>\n",
       "      <td>132.289890</td>\n",
       "      <td>145.871273</td>\n",
       "      <td>142.955217</td>\n",
       "      <td>186.492333</td>\n",
       "      <td>181.068856</td>\n",
       "      <td>145.077864</td>\n",
       "      <td>140.049672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAG</td>\n",
       "      <td>188.687784</td>\n",
       "      <td>193.898131</td>\n",
       "      <td>204.738443</td>\n",
       "      <td>190.429487</td>\n",
       "      <td>214.063479</td>\n",
       "      <td>201.177356</td>\n",
       "      <td>193.965990</td>\n",
       "      <td>210.601167</td>\n",
       "      <td>184.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>146.567975</td>\n",
       "      <td>139.898005</td>\n",
       "      <td>135.925660</td>\n",
       "      <td>137.707653</td>\n",
       "      <td>147.961075</td>\n",
       "      <td>143.154013</td>\n",
       "      <td>190.454780</td>\n",
       "      <td>182.812062</td>\n",
       "      <td>150.768958</td>\n",
       "      <td>139.595393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NAG</td>\n",
       "      <td>188.676135</td>\n",
       "      <td>196.785244</td>\n",
       "      <td>205.439256</td>\n",
       "      <td>188.892741</td>\n",
       "      <td>212.930494</td>\n",
       "      <td>200.193256</td>\n",
       "      <td>195.365942</td>\n",
       "      <td>211.120288</td>\n",
       "      <td>187.642433</td>\n",
       "      <td>...</td>\n",
       "      <td>145.906225</td>\n",
       "      <td>137.965362</td>\n",
       "      <td>135.696930</td>\n",
       "      <td>136.566413</td>\n",
       "      <td>148.512241</td>\n",
       "      <td>147.225655</td>\n",
       "      <td>188.973490</td>\n",
       "      <td>180.972055</td>\n",
       "      <td>150.834480</td>\n",
       "      <td>144.997131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAG</td>\n",
       "      <td>191.597982</td>\n",
       "      <td>198.073910</td>\n",
       "      <td>207.228187</td>\n",
       "      <td>191.359228</td>\n",
       "      <td>216.400508</td>\n",
       "      <td>204.915715</td>\n",
       "      <td>196.750767</td>\n",
       "      <td>212.765273</td>\n",
       "      <td>188.069261</td>\n",
       "      <td>...</td>\n",
       "      <td>148.048014</td>\n",
       "      <td>142.777993</td>\n",
       "      <td>138.571592</td>\n",
       "      <td>139.871011</td>\n",
       "      <td>149.325675</td>\n",
       "      <td>147.267253</td>\n",
       "      <td>191.674436</td>\n",
       "      <td>181.895288</td>\n",
       "      <td>151.418516</td>\n",
       "      <td>144.500663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NAG</td>\n",
       "      <td>191.995746</td>\n",
       "      <td>197.487210</td>\n",
       "      <td>207.555490</td>\n",
       "      <td>190.154033</td>\n",
       "      <td>215.954059</td>\n",
       "      <td>204.451851</td>\n",
       "      <td>195.954535</td>\n",
       "      <td>212.006043</td>\n",
       "      <td>186.626644</td>\n",
       "      <td>...</td>\n",
       "      <td>148.592881</td>\n",
       "      <td>142.369244</td>\n",
       "      <td>141.970623</td>\n",
       "      <td>141.024319</td>\n",
       "      <td>149.555564</td>\n",
       "      <td>144.520580</td>\n",
       "      <td>192.058957</td>\n",
       "      <td>182.758695</td>\n",
       "      <td>151.225190</td>\n",
       "      <td>140.983976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NAG</td>\n",
       "      <td>191.476636</td>\n",
       "      <td>196.328177</td>\n",
       "      <td>204.828122</td>\n",
       "      <td>188.150900</td>\n",
       "      <td>213.861140</td>\n",
       "      <td>200.008922</td>\n",
       "      <td>194.751602</td>\n",
       "      <td>211.031436</td>\n",
       "      <td>185.575462</td>\n",
       "      <td>...</td>\n",
       "      <td>143.536306</td>\n",
       "      <td>138.217633</td>\n",
       "      <td>136.224451</td>\n",
       "      <td>136.080941</td>\n",
       "      <td>147.426301</td>\n",
       "      <td>145.118732</td>\n",
       "      <td>187.869151</td>\n",
       "      <td>181.495041</td>\n",
       "      <td>149.333027</td>\n",
       "      <td>140.820914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NAG</td>\n",
       "      <td>192.241244</td>\n",
       "      <td>194.581874</td>\n",
       "      <td>205.838516</td>\n",
       "      <td>189.231540</td>\n",
       "      <td>212.002525</td>\n",
       "      <td>200.355934</td>\n",
       "      <td>195.068299</td>\n",
       "      <td>210.264522</td>\n",
       "      <td>186.778753</td>\n",
       "      <td>...</td>\n",
       "      <td>145.275712</td>\n",
       "      <td>142.548213</td>\n",
       "      <td>137.708598</td>\n",
       "      <td>135.283471</td>\n",
       "      <td>145.356045</td>\n",
       "      <td>147.134909</td>\n",
       "      <td>189.086293</td>\n",
       "      <td>180.326615</td>\n",
       "      <td>146.928792</td>\n",
       "      <td>142.594888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  aceleracao_agressiva0  aceleracao_agressiva1  aceleracao_agressiva2  \\\n",
       "0   NAG             156.195372             164.150006             187.128103   \n",
       "1   NAG             179.146723             189.445860             197.624226   \n",
       "2   NAG             188.202503             197.142536             204.851447   \n",
       "3   NAG             189.640675             195.403324             206.805417   \n",
       "4   NAG             188.687784             193.898131             204.738443   \n",
       "5   NAG             188.676135             196.785244             205.439256   \n",
       "6   NAG             191.597982             198.073910             207.228187   \n",
       "7   NAG             191.995746             197.487210             207.555490   \n",
       "8   NAG             191.476636             196.328177             204.828122   \n",
       "9   NAG             192.241244             194.581874             205.838516   \n",
       "\n",
       "   aceleracao_agressiva3  aceleracao_agressiva4  aceleracao_agressiva5  \\\n",
       "0             168.341293             210.468254             196.321367   \n",
       "1             179.174447             208.437603             195.636896   \n",
       "2             183.723426             208.943985             195.507899   \n",
       "3             190.431027             215.821046             202.883993   \n",
       "4             190.429487             214.063479             201.177356   \n",
       "5             188.892741             212.930494             200.193256   \n",
       "6             191.359228             216.400508             204.915715   \n",
       "7             190.154033             215.954059             204.451851   \n",
       "8             188.150900             213.861140             200.008922   \n",
       "9             189.231540             212.002525             200.355934   \n",
       "\n",
       "   aceleracao_agressiva6  aceleracao_agressiva7  aceleracao_agressiva8  ...  \\\n",
       "0             177.595807             214.772692             166.894221  ...   \n",
       "1             195.555334             213.071510             184.495338  ...   \n",
       "2             191.363939             208.260254             181.370713  ...   \n",
       "3             190.642412             207.585205             180.842636  ...   \n",
       "4             193.965990             210.601167             184.971489  ...   \n",
       "5             195.365942             211.120288             187.642433  ...   \n",
       "6             196.750767             212.765273             188.069261  ...   \n",
       "7             195.954535             212.006043             186.626644  ...   \n",
       "8             194.751602             211.031436             185.575462  ...   \n",
       "9             195.068299             210.264522             186.778753  ...   \n",
       "\n",
       "   curva_esquerda_agressiva1  curva_esquerda_agressiva2  \\\n",
       "0                 134.648802                 131.349655   \n",
       "1                 140.005523                 130.059800   \n",
       "2                 146.358798                 136.656233   \n",
       "3                 140.476681                 137.316624   \n",
       "4                 146.567975                 139.898005   \n",
       "5                 145.906225                 137.965362   \n",
       "6                 148.048014                 142.777993   \n",
       "7                 148.592881                 142.369244   \n",
       "8                 143.536306                 138.217633   \n",
       "9                 145.275712                 142.548213   \n",
       "\n",
       "   curva_esquerda_agressiva3  curva_esquerda_agressiva4  \\\n",
       "0                 127.787261                 125.194055   \n",
       "1                 128.958115                 127.738862   \n",
       "2                 132.964335                 133.870663   \n",
       "3                 131.471869                 132.289890   \n",
       "4                 135.925660                 137.707653   \n",
       "5                 135.696930                 136.566413   \n",
       "6                 138.571592                 139.871011   \n",
       "7                 141.970623                 141.024319   \n",
       "8                 136.224451                 136.080941   \n",
       "9                 137.708598                 135.283471   \n",
       "\n",
       "   curva_esquerda_agressiva5  curva_esquerda_agressiva6  \\\n",
       "0                 136.839273                 121.556602   \n",
       "1                 148.062329                 139.819652   \n",
       "2                 145.985343                 148.594318   \n",
       "3                 145.871273                 142.955217   \n",
       "4                 147.961075                 143.154013   \n",
       "5                 148.512241                 147.225655   \n",
       "6                 149.325675                 147.267253   \n",
       "7                 149.555564                 144.520580   \n",
       "8                 147.426301                 145.118732   \n",
       "9                 145.356045                 147.134909   \n",
       "\n",
       "   curva_esquerda_agressiva7  curva_esquerda_agressiva8  \\\n",
       "0                 172.023376                 172.619455   \n",
       "1                 184.756366                 174.633300   \n",
       "2                 190.612853                 176.485091   \n",
       "3                 186.492333                 181.068856   \n",
       "4                 190.454780                 182.812062   \n",
       "5                 188.973490                 180.972055   \n",
       "6                 191.674436                 181.895288   \n",
       "7                 192.058957                 182.758695   \n",
       "8                 187.869151                 181.495041   \n",
       "9                 189.086293                 180.326615   \n",
       "\n",
       "   curva_esquerda_agressiva9  curva_esquerda_agressiva10  \n",
       "0                 133.983289                  120.291350  \n",
       "1                 151.950375                  139.542378  \n",
       "2                 144.656271                  145.430741  \n",
       "3                 145.077864                  140.049672  \n",
       "4                 150.768958                  139.595393  \n",
       "5                 150.834480                  144.997131  \n",
       "6                 151.418516                  144.500663  \n",
       "7                 151.225190                  140.983976  \n",
       "8                 149.333027                  140.820914  \n",
       "9                 146.928792                  142.594888  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData[226].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize Train Data\n",
    "#Balance it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  60.0  %  is complete\n",
      "87 min has time for calculaton Model\n"
     ]
    }
   ],
   "source": [
    "#dont run this part\n",
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "t1=time.time()\n",
    "n,k=0,12*50\n",
    "\n",
    "Result={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wid in Result:\n",
    "    data=TrainData[wid].drop('label',1)\n",
    "    label=TrainData[wid].label\n",
    "    #\n",
    "    for Max_depth in range(1,13):\n",
    "        estimator = Id3Estimator(max_depth=Max_depth, min_samples_split=1, prune=True,\n",
    "                        gain_ratio=True, min_entropy_decrease=0, is_repeating=True)\n",
    "        #run it in itaraion for the best trees\n",
    "        NUMBER_OF_TEST=10\n",
    "        temp=list()\n",
    "        for NT in range(NUMBER_OF_TEST):\n",
    "            clear_output(wait=True)\n",
    "            n=n+1\n",
    "            print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "            estimator.fit(data,label , check_input=True)\n",
    "            ACC=accuracy_score(y_true=label,y_pred=estimator.predict(data))\n",
    "            temp.append((ACC,deepcopy(estimator)))\n",
    "        temp_index=[(x[0],i) for i,x in enumerate(temp)]\n",
    "        temp_index.sort()\n",
    "        Acc=temp[temp_index[-1][1]][0]\n",
    "        estimator=temp[temp_index[-1][1]][1]\n",
    "        Result[wid].append((Acc,deepcopy(estimator)))\n",
    "\n",
    "with open(\"Model_new_1.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Result, fp)\n",
    "t2=time.time()\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "with open(\"Model_new_1.txt\", \"rb\") as fp:\n",
    "    Result = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99127631329414\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                           NAG       0.99      1.00      1.00      5198\n",
      " troca_faixa_direita_agressiva       1.00      0.43      0.60        28\n",
      "troca_faixa_esquerda_agressiva       0.90      0.40      0.56        47\n",
      "\n",
      "                      accuracy                           0.99      5273\n",
      "                     macro avg       0.97      0.61      0.72      5273\n",
      "                  weighted avg       0.99      0.99      0.99      5273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=4\n",
    "wid=126\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989517819706499\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "             NAG       0.99      1.00      0.99      3277\n",
      "freada_agressiva       1.00      0.44      0.61        62\n",
      "\n",
      "        accuracy                           0.99      3339\n",
      "       macro avg       0.99      0.72      0.80      3339\n",
      "    weighted avg       0.99      0.99      0.99      3339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=4\n",
    "wid=186\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196091494559183\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                     NAG       0.92      1.00      0.96      3987\n",
      "    aceleracao_agressiva       1.00      0.03      0.06        97\n",
      " curva_direita_agressiva       0.98      0.30      0.45       213\n",
      "curva_esquerda_agressiva       1.00      0.43      0.60       206\n",
      "\n",
      "                accuracy                           0.92      4503\n",
      "               macro avg       0.98      0.44      0.52      4503\n",
      "            weighted avg       0.93      0.92      0.90      4503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=4\n",
    "wid=226\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overfit model!\n",
    "Overfit_model={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wid in Overfit_model:\n",
    "    data=TrainData[wid].drop('label',1)\n",
    "    label=TrainData[wid].label\n",
    "    #\n",
    "    estimator = Id3Estimator(max_depth=100, min_samples_split=1, prune=True,\n",
    "                    gain_ratio=True, min_entropy_decrease=0, is_repeating=True)\n",
    "    #run it in itaraion for the best trees\n",
    "    NUMBER_OF_TEST=10\n",
    "    temp=list()\n",
    "    for NT in range(NUMBER_OF_TEST):\n",
    "        estimator.fit(data,label , check_input=True)\n",
    "        ACC=accuracy_score(y_true=label,y_pred=estimator.predict(data))\n",
    "        temp.append((ACC,deepcopy(estimator)))\n",
    "    temp_index=[(x[0],i) for i,x in enumerate(temp)]\n",
    "    temp_index.sort()\n",
    "    Acc=temp[temp_index[-1][1]][0]\n",
    "    estimator=temp[temp_index[-1][1]][1]\n",
    "    Overfit_model[wid]=(Acc,deepcopy(estimator))\n",
    "\n",
    "with open(\"TrainData_test_l_1.txt\", \"wb\") as fp:\n",
    "    pickle.dump((Overfit_model), fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wid=226\n",
    "data=TrainData[wid].drop('label',1)\n",
    "label=TrainData[wid].label\n",
    "print(classification_report(label, Overfit_model[wid][1].predict(data)))\n",
    "#its completely ovefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in wid window:\n",
    "    estimator=Result[wid][5][1]\n",
    "    x={x for x in estimator.predict(Test_new[wid])}\n",
    "    print(f\" {wid} is : {x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "x=data.columns[30]\n",
    "rep=re.compile(r'(\\w+)(\\d+)')\n",
    "mo=rep.findall(x)[0]\n",
    "print(mo[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot charts for find the optimom\n",
    "Y1=[x[0]for x in Result[226]]\n",
    "Y2=[x[0]for x in Result[186]]\n",
    "Y3=[x[0]for x in Result[126]]\n",
    "\n",
    "X=range(1,11)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(X,Y1, linestyle='-', linewidth=2,c='r')\n",
    "ax.plot(X,Y2, linestyle='-', linewidth=2,c='g')\n",
    "ax.plot(X,Y3, linestyle='-', linewidth=2,c='b')\n",
    "\n",
    "ax.legend();\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
