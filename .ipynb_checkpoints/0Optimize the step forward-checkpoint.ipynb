{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ya Khode Khoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def color_map_color(value, cmap_name='coolwarm', vmin=0, vmax=10):\n",
    "    # norm = plt.Normalize(vmin, vmax)\n",
    "    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = cm.get_cmap(cmap_name)  # PiYG\n",
    "    rgb = cmap(norm(abs(value)))[:3]  # will return rgba, we take only first 3 so we get rgb\n",
    "    color = matplotlib.colors.rgb2hex(rgb)\n",
    "    return color\n",
    "cl=['r','g','b','c','m','y','k']\n",
    "color=dict()\n",
    "for i,el in enumerate(cl):\n",
    "    color.update({i:el})\n",
    "#extract the labels for clutering precision its for after clustering\n",
    "def time_convertor(x):\n",
    "    s,h,m=0,0,0\n",
    "    s=round(x%60,2)\n",
    "    m=int(x/60)\n",
    "    h=int(m/60)\n",
    "    m=m%60\n",
    "    time=str(h)+':'+str(m)+':'+str(s)\n",
    "    return pd.to_datetime('1970-01-01 '+time)\n",
    "\n",
    "\n",
    "# Display figures inline in Jupyter notebook\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(15, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "with open(\"normalized_data.txt\", \"rb\") as fp:\n",
    "        dfRaw = pickle.load(fp)\n",
    "        \n",
    "def get_label(number,df):\n",
    "    label_event_lenght=dict()\n",
    "    df=pd.read_csv(f'{number}\\\\groundTruth.csv')\n",
    "    df['length']=df.en-df.st\n",
    "    for event , dft in df.groupby('evento'):\n",
    "        if (event in label_event_lenght):\n",
    "            label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "        else:\n",
    "            label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "    df['st_time']=df.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "    df['en_time']=df.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "    df=df.drop('st',1).drop('en',1).drop('length',1)\n",
    "    evented_label=list()\n",
    "    for i in range(len(df)):\n",
    "        evented_label.append((df.iloc[i][0],df.iloc[i][1],df.iloc[i][2]))\n",
    "    eve=pd.DataFrame(evented_label)\n",
    "    eve[3]=[f'evented_label_{number}' for x in evented_label]\n",
    "    return eve\n",
    "Ev=[get_label(dfRaw[x][0],dfRaw[x][1]) for x in range(len(dfRaw))]\n",
    "evented_label_All=pd.concat(Ev).reset_index().drop('index',1)\n",
    "\n",
    "window={226:['curva_direita_agressiva','curva_esquerda_agressiva','aceleracao_agressiva'],\n",
    "        126:['troca_faixa_direita_agressiva','troca_faixa_esquerda_agressiva'],\n",
    "        186:['freada_agressiva']\n",
    "       }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'window' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fa9774674139>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDF\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfRaw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mte\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0mte\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTempEvent_genarator_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mtemp_event_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'window' is not defined"
     ]
    }
   ],
   "source": [
    "#optimaze the forward step for the labeled dataset\n",
    "#param for optimization\n",
    "\n",
    "\n",
    "t1=time.time()\n",
    "def TempEvent_genarator_new(Lambda,df,L,i):\n",
    "    M=int((L)*Lambda)\n",
    "    temp_event=list()\n",
    "    pointer=0\n",
    "    stop=False\n",
    "    #go on timeserise for event extraction\n",
    "    while stop!=True:\n",
    "        clear_output(wait=True)\n",
    "        pointer=pointer + M\n",
    "        l_min=pointer-int(L/2)\n",
    "        l_max=pointer+int(L/2)\n",
    "        if l_max<0:\n",
    "            l_max=L/2\n",
    "        if (l_min<0):\n",
    "            l_min=0\n",
    "        if (l_max>len(df)):\n",
    "            l_max=len(df)\n",
    "            stop=True\n",
    "        print('extraction ',l_max/len(df),' % of ',i,' is complete')\n",
    "        temp_event.append(df[l_min:l_max])\n",
    "    return temp_event\n",
    "\n",
    "def has_overlap(A_start, A_end, B_start, B_end):\n",
    "    latest_start = max(A_start, B_start)\n",
    "    earliest_end = min(A_end, B_end)\n",
    "    return latest_start <= earliest_end\n",
    "\n",
    "def export_labels(tempevent,evented_label):\n",
    "    EvL=pd.DataFrame(evented_label)\n",
    "    Labels={\n",
    "          226:[],\n",
    "          126:[],\n",
    "          186:[],\n",
    "           }\n",
    "    for i,wind in enumerate(Labels):\n",
    "        label=['NAG' for x in tempevent[i][1]]\n",
    "        for name in tempevent[i][0]:\n",
    "            el=[(x[1],x[2]) for x in EvL.iloc if x[0]==name]\n",
    "            for j,te in enumerate(tempevent[i][1]):\n",
    "                    sta =te.index[0]\n",
    "                    ena =te.index[-1]\n",
    "                    for stb,enb in el:\n",
    "                        if has_overlap(sta,ena,stb,enb):\n",
    "                            label[j]=name\n",
    "        Labels[wind]=label\n",
    "    return Labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LAMBDA=list()\n",
    "\n",
    "for Lambda in np.linspace(0.1,1,10):\n",
    "    temp_event_test=list()\n",
    "    for l,DF in enumerate([x[1] for x in dfRaw]):\n",
    "        te=list()\n",
    "        for i,lw in enumerate(window):\n",
    "            te.append((window[lw],TempEvent_genarator_new(Lambda,DF,lw,i+1)))\n",
    "        temp_event_test.append(te)\n",
    "\n",
    "    #make it dataframe\n",
    "    Data_test={\n",
    "          226:[],\n",
    "          126:[],\n",
    "          186:[],\n",
    "           }\n",
    "    for i,temp in enumerate(temp_event_test):\n",
    "        TempEv={\n",
    "                  226:[ x for x in temp_event_test[i][0][1] ],\n",
    "                  126:[ x for x in temp_event_test[i][1][1] ],\n",
    "                  186:[ x for x in temp_event_test[i][2][1] ],\n",
    "                   }\n",
    "        Label=export_labels(temp_event_test[i],Ev[i])\n",
    "        #merge together\n",
    "        for wind in Data_test:\n",
    "            for j in range(len(TempEv[wind])):\n",
    "                Data_test[wind].append((Label[wind][j],TempEv[wind][j]))\n",
    "\n",
    "    #calculate distance\n",
    "    k,n=0,0\n",
    "    num_event=dict(evented_label_All.groupby(0).size())\n",
    "    for lenght in window:\n",
    "        for name in window[lenght]:\n",
    "            k=k+len(Data_test[lenght])*num_event[name]\n",
    "\n",
    "    Data_DS_test={\n",
    "          226:[],\n",
    "          126:[],\n",
    "          186:[],\n",
    "           }\n",
    "\n",
    "    for wind in Data_test:\n",
    "        for label,event in Data_test[wind]:\n",
    "             #---------for each Data-distance from events----------\n",
    "            Y=list()\n",
    "            for from_event,dfe in evented_label_All.groupby(0):\n",
    "                if from_event in window[wind]:\n",
    "                    X=list()\n",
    "                    #____for each event_distance from each label_____\n",
    "                    for el in dfe.iloc:\n",
    "                        clear_output(wait=True)\n",
    "                        n=n+1\n",
    "                        print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "                        if   el[3]=='evented_label_16':\n",
    "                            X.append(fastdtw(event,dfRaw[0][1][el[1]:el[2]])[0])\n",
    "                        elif el[3]=='evented_label_17':\n",
    "                            X.append(fastdtw(event,dfRaw[1][1][el[1]:el[2]])[0])\n",
    "                        elif el[3]=='evented_label_21':\n",
    "                            X.append(fastdtw(event,dfRaw[2][1][el[1]:el[2]])[0])\n",
    "                        elif el[3]=='evented_label_22':\n",
    "                            X.append(fastdtw(event,dfRaw[3][1][el[1]:el[2]])[0])\n",
    "                    #_________________________________________________\n",
    "                    Y.append((from_event,X))\n",
    "            Data_DS_test[wind].append((label,Y))\n",
    "            #------------------------------------------------------\n",
    "\n",
    "    #prepare dataset for labeling\n",
    "    TrainData_test=dict()\n",
    "    for win in Data_DS_test:\n",
    "        x=Data_DS_test[win]\n",
    "        dumy_list=list()\n",
    "        for events in x:\n",
    "            dumy_dict=dict()\n",
    "            dumy_dict.update({'label':events[0]})\n",
    "            for name , event in events[1]:\n",
    "                for tag,number in enumerate(event):\n",
    "                    dumy_dict.update({name+str(tag):number})\n",
    "            dumy_list.append(dumy_dict)\n",
    "        TrainData_test.update({win:pd.DataFrame(dumy_list)})\n",
    "    LAMBDA.append((Lambda,deepcopy(TrainData_test)))\n",
    "\n",
    "with open(\"TrainData_test_Optimize_Forward_step.txt\", \"wb\") as fp:\n",
    "    pickle.dump(LAMBDA, fp)\n",
    "t2=time.time()\n",
    "print(round((t2-t1)/60) ,'min has time left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "with open(\"OverFit_model.txt\", \"rb\") as fp:\n",
    "    Result = pickle.load(fp)\n",
    "    \n",
    "#with open(\"TrainData_test_l_1.txt\", \"rb\") as fp:\n",
    "    #temp_event_test,TrainData_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wid=226\n",
    "Max_depth=8\n",
    "TrainData_test=LAMBDA[1][1]\n",
    "\n",
    "\n",
    "data=TrainData_test[wid].drop('label',1)\n",
    "label=TrainData_test[wid].label\n",
    "\n",
    "estimator=Result[wid][1]\n",
    "print(classification_report(label, estimator.predict(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
