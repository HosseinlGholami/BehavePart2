{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the name of GOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def color_map_color(value, cmap_name='coolwarm', vmin=0, vmax=10):\n",
    "    # norm = plt.Normalize(vmin, vmax)\n",
    "    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = cm.get_cmap(cmap_name)  # PiYG\n",
    "    rgb = cmap(norm(abs(value)))[:3]  # will return rgba, we take only first 3 so we get rgb\n",
    "    color = matplotlib.colors.rgb2hex(rgb)\n",
    "    return color\n",
    "cl=['r','g','b','c','m','y','k']\n",
    "color=dict()\n",
    "for i,el in enumerate(cl):\n",
    "    color.update({i:el})\n",
    "#extract the labels for clutering precision its for after clustering\n",
    "def time_convertor(x):\n",
    "    s,h,m=0,0,0\n",
    "    s=round(x%60,2)\n",
    "    m=int(x/60)\n",
    "    h=int(m/60)\n",
    "    m=m%60\n",
    "    time=str(h)+':'+str(m)+':'+str(s)\n",
    "    return pd.to_datetime('1970-01-01 '+time)\n",
    "\n",
    "\n",
    "# Display figures inline in Jupyter notebook\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(15, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_read\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('16\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('16\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df1 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('17\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('17\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df2 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('20\\\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('20\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df3 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('21\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('21\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "df4 = pd.concat([dfa, dfg], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_event_lenght=dict()\n",
    "#prepare Labeled dataset on 16\n",
    "dfl=pd.read_csv('16\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "        \n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_1=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_1.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 17\n",
    "dfl=pd.read_csv('17\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_2=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_2.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 20\n",
    "dfl=pd.read_csv('20\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_3=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_3.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 21\n",
    "dfl=pd.read_csv('21\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_4=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_4.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve1=pd.DataFrame(evented_label_1)\n",
    "eve1[3]=['evented_label_1' for x in evented_label_1]\n",
    "\n",
    "eve2=pd.DataFrame(evented_label_2)\n",
    "eve2[3]=['evented_label_2' for x in evented_label_2]\n",
    "\n",
    "eve3=pd.DataFrame(evented_label_3)\n",
    "eve3[3]=['evented_label_3' for x in evented_label_3]\n",
    "\n",
    "eve4=pd.DataFrame(evented_label_4)\n",
    "eve4[3]=['evented_label_4' for x in evented_label_4]\n",
    "\n",
    "evented_label_All=pd.concat([eve1, eve2,eve3,eve4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>1970-01-01 00:00:02.000</td>\n",
       "      <td>1970-01-01 00:00:06.500</td>\n",
       "      <td>evented_label_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curva_direita_agressiva</td>\n",
       "      <td>1970-01-01 00:00:19.500</td>\n",
       "      <td>1970-01-01 00:00:23.500</td>\n",
       "      <td>evented_label_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>1970-01-01 00:00:30.000</td>\n",
       "      <td>1970-01-01 00:00:33.500</td>\n",
       "      <td>evented_label_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>curva_direita_agressiva</td>\n",
       "      <td>1970-01-01 00:01:35.000</td>\n",
       "      <td>1970-01-01 00:01:38.000</td>\n",
       "      <td>evented_label_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>curva_esquerda_agressiva</td>\n",
       "      <td>1970-01-01 00:04:07.000</td>\n",
       "      <td>1970-01-01 00:04:11.500</td>\n",
       "      <td>evented_label_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>1970-01-01 00:09:25.000</td>\n",
       "      <td>1970-01-01 00:09:27.800</td>\n",
       "      <td>evented_label_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>1970-01-01 00:11:40.000</td>\n",
       "      <td>1970-01-01 00:11:43.200</td>\n",
       "      <td>evented_label_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aceleracao_agressiva</td>\n",
       "      <td>1970-01-01 00:11:54.000</td>\n",
       "      <td>1970-01-01 00:11:57.000</td>\n",
       "      <td>evented_label_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>1970-01-01 00:12:31.500</td>\n",
       "      <td>1970-01-01 00:12:34.700</td>\n",
       "      <td>evented_label_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>evento_nao_agressivo</td>\n",
       "      <td>1970-01-01 00:13:04.600</td>\n",
       "      <td>1970-01-01 00:13:07.800</td>\n",
       "      <td>evented_label_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                       1                       2  \\\n",
       "0       evento_nao_agressivo 1970-01-01 00:00:02.000 1970-01-01 00:00:06.500   \n",
       "1    curva_direita_agressiva 1970-01-01 00:00:19.500 1970-01-01 00:00:23.500   \n",
       "2       evento_nao_agressivo 1970-01-01 00:00:30.000 1970-01-01 00:00:33.500   \n",
       "3    curva_direita_agressiva 1970-01-01 00:01:35.000 1970-01-01 00:01:38.000   \n",
       "4   curva_esquerda_agressiva 1970-01-01 00:04:07.000 1970-01-01 00:04:11.500   \n",
       "..                       ...                     ...                     ...   \n",
       "17      aceleracao_agressiva 1970-01-01 00:09:25.000 1970-01-01 00:09:27.800   \n",
       "18      aceleracao_agressiva 1970-01-01 00:11:40.000 1970-01-01 00:11:43.200   \n",
       "19      aceleracao_agressiva 1970-01-01 00:11:54.000 1970-01-01 00:11:57.000   \n",
       "20      evento_nao_agressivo 1970-01-01 00:12:31.500 1970-01-01 00:12:34.700   \n",
       "21      evento_nao_agressivo 1970-01-01 00:13:04.600 1970-01-01 00:13:07.800   \n",
       "\n",
       "                  3  \n",
       "0   evented_label_1  \n",
       "1   evented_label_1  \n",
       "2   evented_label_1  \n",
       "3   evented_label_1  \n",
       "4   evented_label_1  \n",
       "..              ...  \n",
       "17  evented_label_4  \n",
       "18  evented_label_4  \n",
       "19  evented_label_4  \n",
       "20  evented_label_4  \n",
       "21  evented_label_4  \n",
       "\n",
       "[69 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evented_label_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('curva_direita_agressiva', 225),\n",
       " ('curva_esquerda_agressiva', 225),\n",
       " ('evento_nao_agressivo', 225),\n",
       " ('troca_faixa_direita_agressiva', 125),\n",
       " ('aceleracao_agressiva', 245),\n",
       " ('freada_agressiva', 185),\n",
       " ('troca_faixa_esquerda_agressiva', 120)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=(df2.index[6]-df3.index[5]).total_seconds()\n",
    "window_list=list()\n",
    "for event in label_event_lenght:\n",
    "    window_list.append((event,round(max(label_event_lenght[event])/rate)))\n",
    "window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supervised\n",
    "window={226:['curva_direita_agressiva','curva_esquerda_agressiva','aceleracao_agressiva'],\n",
    "        126:['troca_faixa_direita_agressiva','troca_faixa_esquerda_agressiva'],\n",
    "        186:['freada_agressiva']\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction  1.0  % of  3  is complete\n"
     ]
    }
   ],
   "source": [
    "#Dont RUN this part\n",
    "#we should optimize M\n",
    "#lengh of random event\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "def TempEvent_genarator(df,L,i):\n",
    "    M=round(random.gauss(0.55,0.5)*L/2)\n",
    "    temp_event=list()\n",
    "    pointer=0\n",
    "    stop=False\n",
    "    #go on timeserise for event extraction\n",
    "    while stop!=True:\n",
    "        clear_output(wait=True)\n",
    "        pointer=pointer + M\n",
    "        l_min=pointer-int(L/2)\n",
    "        l_max=pointer+int(L/2)\n",
    "        if l_max<0:\n",
    "            l_max=L/2\n",
    "        if (l_min<0):\n",
    "            l_min=0\n",
    "        if (l_max>len(df)):\n",
    "            l_max=len(df)\n",
    "            stop=True\n",
    "        print('extraction ',l_max/len(df),' % of ',i,' is complete')\n",
    "        temp_event.append(df[l_min:l_max])\n",
    "    return temp_event\n",
    "\n",
    "\n",
    "temp_event=list()\n",
    "for l,DF in enumerate([df1,df2,df3,df4]):\n",
    "    te=list()\n",
    "    for i,lw in enumerate(window):\n",
    "        te.append((window[lw],TempEvent_genarator(DF,lw,i+1)))\n",
    "    temp_event.append(te)\n",
    "\n",
    "with open(\"temp_event.txt\", \"wb\") as fp:\n",
    "    pickle.dump(temp_event, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  100.0  %  is complete\n",
      "241 min has time for calculaton distant\n"
     ]
    }
   ],
   "source": [
    "#calculate tempevnt with labdeled event\n",
    "def calculate_distance(temp_event,evented_label):\n",
    "    Dum=evented_label.groupby(0).size()\n",
    "    n=0\n",
    "    k=0\n",
    "    for L , AEV in temp_event:\n",
    "        for i in L: \n",
    "            k=k+len(AEV)*Dum[i]\n",
    "\n",
    "    EVENT_DS=dict()\n",
    "    for L , AEV in temp_event:\n",
    "        for eve_name in L:\n",
    "            Y=list()\n",
    "            for EV in AEV:\n",
    "                X=list()\n",
    "                for eve,dfe in evented_label.groupby(0):\n",
    "                    if eve==eve_name:\n",
    "                        for el in dfe.iloc:\n",
    "                            clear_output(wait=True)\n",
    "                            n=n+1\n",
    "                            print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "                            if   el[3]=='evented_label_1':\n",
    "                                X.append(fastdtw(EV,df1[el[1]:el[2]])[0])\n",
    "                            elif el[3]=='evented_label_2':\n",
    "                                X.append(fastdtw(EV,df2[el[1]:el[2]])[0])\n",
    "                            elif el[3]=='evented_label_3':\n",
    "                                X.append(fastdtw(EV,df3[el[1]:el[2]])[0])\n",
    "                            elif el[3]=='evented_label_4':\n",
    "                                X.append(fastdtw(EV,df4[el[1]:el[2]])[0])\n",
    "                Y.append(X)\n",
    "            EVENT_DS.update({eve_name:Y})\n",
    "    return EVENT_DS\n",
    "\n",
    "\n",
    "t1=time.time()\n",
    "EVENT_DS=list()\n",
    "for TE in temp_event:\n",
    "    EVENT_DS.append(calculate_distance(TE,evented_label_All))\n",
    "\n",
    "t2=time.time()\n",
    "with open(\"Disstance.txt\", \"wb\") as fp:\n",
    "    pickle.dump(EVENT_DS, fp)\n",
    "\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton distant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp_event.txt\", \"rb\") as fp:\n",
    "    temp_event = pickle.load(fp)\n",
    "with open(\"Disstance.txt\", \"rb\") as fp:\n",
    "    EVENT_DS = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_overlap(A_start, A_end, B_start, B_end):\n",
    "    latest_start = max(A_start, B_start)\n",
    "    earliest_end = min(A_end, B_end)\n",
    "    return latest_start <= earliest_end\n",
    "def export_labels(EVENT_DS,temp_event,evented_label):\n",
    "    Labels=dict()\n",
    "    for name in EVENT_DS:\n",
    "        if name in {x[0] for x in evented_label}:\n",
    "            label=list()\n",
    "            for i in range(0,3):\n",
    "                if name in temp_event[i][0]:\n",
    "                    el=[(x[1],x[2]) for x in evented_label if x[0]==name]                    \n",
    "                    for te in temp_event[i][1]:\n",
    "                        sta =te.index[0]\n",
    "                        ena =te.index[-1]\n",
    "                        D=False\n",
    "                        for stb,enb in el:\n",
    "                            if has_overlap(sta,ena,stb,enb):\n",
    "                                D=True\n",
    "                        if D==False:\n",
    "                            label.append(False)\n",
    "                        else:\n",
    "                            label.append(True)\n",
    "            Labels.update({name:label})\n",
    "    return Labels\n",
    "\n",
    "def export_dataframe(ED,evented_label):\n",
    "    Dt=dict()\n",
    "    for name in ED:\n",
    "        if name in {x[0] for x in evented_label}:\n",
    "            df=pd.DataFrame(ED[name])\n",
    "            Dt.update({name:df})\n",
    "    return Dt\n",
    "\n",
    "#prepare each data with label\n",
    "Labeled_Event=[evented_label_1,evented_label_2,evented_label_3,evented_label_4]\n",
    "Data_Frame=list()\n",
    "for i in range(4):\n",
    "    Data_dict=export_dataframe(EVENT_DS[i],Labeled_Event[i])\n",
    "    Label_dict=export_labels( EVENT_DS[i],temp_event[i],Labeled_Event[i])\n",
    "    for name in Data_dict :\n",
    "        Data_dict[name]['label']=Label_dict[name]\n",
    "    Data_Frame.append(Data_dict)\n",
    "\n",
    "\n",
    "#prepare as data frame    \n",
    "feature_name=list(pd.core.common.flatten(window.values()))\n",
    "Train_Data={x:None for x in feature_name}\n",
    "\n",
    "for name in feature_name:\n",
    "    for df in Data_Frame:\n",
    "        if name in df:\n",
    "            if type(Train_Data[name])==None:\n",
    "                Train_Data[name]=df[name]\n",
    "            else:\n",
    "                Train_Data[name]=pd.concat([df[name],Train_Data[name]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1062.015535</td>\n",
       "      <td>952.436789</td>\n",
       "      <td>920.127561</td>\n",
       "      <td>1096.316454</td>\n",
       "      <td>995.629507</td>\n",
       "      <td>1143.001716</td>\n",
       "      <td>1110.641003</td>\n",
       "      <td>1311.701689</td>\n",
       "      <td>1163.363101</td>\n",
       "      <td>1534.527044</td>\n",
       "      <td>1375.345204</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1094.586953</td>\n",
       "      <td>965.045920</td>\n",
       "      <td>944.507193</td>\n",
       "      <td>1115.913814</td>\n",
       "      <td>1020.728878</td>\n",
       "      <td>1162.351957</td>\n",
       "      <td>1132.215259</td>\n",
       "      <td>1320.968916</td>\n",
       "      <td>1165.415199</td>\n",
       "      <td>1569.512715</td>\n",
       "      <td>1407.334926</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1147.217060</td>\n",
       "      <td>992.942614</td>\n",
       "      <td>978.602362</td>\n",
       "      <td>1141.387087</td>\n",
       "      <td>1048.371460</td>\n",
       "      <td>1195.109873</td>\n",
       "      <td>1142.754726</td>\n",
       "      <td>1341.778559</td>\n",
       "      <td>1191.336390</td>\n",
       "      <td>1567.514577</td>\n",
       "      <td>1452.186938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1183.879516</td>\n",
       "      <td>1035.486601</td>\n",
       "      <td>1022.961876</td>\n",
       "      <td>1170.632577</td>\n",
       "      <td>1081.989275</td>\n",
       "      <td>1245.865721</td>\n",
       "      <td>1143.940665</td>\n",
       "      <td>1329.952034</td>\n",
       "      <td>1201.132482</td>\n",
       "      <td>1554.718536</td>\n",
       "      <td>1479.840019</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1208.393546</td>\n",
       "      <td>1076.152739</td>\n",
       "      <td>1080.891942</td>\n",
       "      <td>1211.080681</td>\n",
       "      <td>1116.779633</td>\n",
       "      <td>1297.881611</td>\n",
       "      <td>1143.872470</td>\n",
       "      <td>1330.538820</td>\n",
       "      <td>1211.034507</td>\n",
       "      <td>1574.589316</td>\n",
       "      <td>1506.577674</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>1135.905282</td>\n",
       "      <td>1064.879507</td>\n",
       "      <td>1093.688986</td>\n",
       "      <td>1136.422309</td>\n",
       "      <td>1074.254382</td>\n",
       "      <td>1337.926759</td>\n",
       "      <td>1265.584614</td>\n",
       "      <td>1485.265977</td>\n",
       "      <td>1195.881876</td>\n",
       "      <td>1495.278540</td>\n",
       "      <td>1401.147746</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>1137.813669</td>\n",
       "      <td>1088.500072</td>\n",
       "      <td>1085.658285</td>\n",
       "      <td>1131.980198</td>\n",
       "      <td>1083.279235</td>\n",
       "      <td>1337.672591</td>\n",
       "      <td>1266.083956</td>\n",
       "      <td>1482.139479</td>\n",
       "      <td>1197.413229</td>\n",
       "      <td>1489.821675</td>\n",
       "      <td>1400.849971</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>1147.196106</td>\n",
       "      <td>1063.992134</td>\n",
       "      <td>1091.683291</td>\n",
       "      <td>1123.775901</td>\n",
       "      <td>1084.130372</td>\n",
       "      <td>1346.251035</td>\n",
       "      <td>1266.800915</td>\n",
       "      <td>1470.657234</td>\n",
       "      <td>1210.925569</td>\n",
       "      <td>1486.199961</td>\n",
       "      <td>1405.359836</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>1158.574733</td>\n",
       "      <td>1097.363589</td>\n",
       "      <td>1079.547271</td>\n",
       "      <td>1136.357523</td>\n",
       "      <td>1100.892220</td>\n",
       "      <td>1348.180709</td>\n",
       "      <td>1285.598047</td>\n",
       "      <td>1484.681353</td>\n",
       "      <td>1212.264628</td>\n",
       "      <td>1493.099443</td>\n",
       "      <td>1412.263085</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>1094.567935</td>\n",
       "      <td>916.889615</td>\n",
       "      <td>918.269347</td>\n",
       "      <td>1057.232814</td>\n",
       "      <td>966.811348</td>\n",
       "      <td>1125.314571</td>\n",
       "      <td>1079.217718</td>\n",
       "      <td>1288.912313</td>\n",
       "      <td>1117.920486</td>\n",
       "      <td>1475.825011</td>\n",
       "      <td>1370.142915</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3061 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4  \\\n",
       "0     1062.015535   952.436789   920.127561  1096.316454   995.629507   \n",
       "1     1094.586953   965.045920   944.507193  1115.913814  1020.728878   \n",
       "2     1147.217060   992.942614   978.602362  1141.387087  1048.371460   \n",
       "3     1183.879516  1035.486601  1022.961876  1170.632577  1081.989275   \n",
       "4     1208.393546  1076.152739  1080.891942  1211.080681  1116.779633   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3056  1135.905282  1064.879507  1093.688986  1136.422309  1074.254382   \n",
       "3057  1137.813669  1088.500072  1085.658285  1131.980198  1083.279235   \n",
       "3058  1147.196106  1063.992134  1091.683291  1123.775901  1084.130372   \n",
       "3059  1158.574733  1097.363589  1079.547271  1136.357523  1100.892220   \n",
       "3060  1094.567935   916.889615   918.269347  1057.232814   966.811348   \n",
       "\n",
       "                5            6            7            8            9  \\\n",
       "0     1143.001716  1110.641003  1311.701689  1163.363101  1534.527044   \n",
       "1     1162.351957  1132.215259  1320.968916  1165.415199  1569.512715   \n",
       "2     1195.109873  1142.754726  1341.778559  1191.336390  1567.514577   \n",
       "3     1245.865721  1143.940665  1329.952034  1201.132482  1554.718536   \n",
       "4     1297.881611  1143.872470  1330.538820  1211.034507  1574.589316   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3056  1337.926759  1265.584614  1485.265977  1195.881876  1495.278540   \n",
       "3057  1337.672591  1266.083956  1482.139479  1197.413229  1489.821675   \n",
       "3058  1346.251035  1266.800915  1470.657234  1210.925569  1486.199961   \n",
       "3059  1348.180709  1285.598047  1484.681353  1212.264628  1493.099443   \n",
       "3060  1125.314571  1079.217718  1288.912313  1117.920486  1475.825011   \n",
       "\n",
       "               10  label  \n",
       "0     1375.345204  False  \n",
       "1     1407.334926  False  \n",
       "2     1452.186938  False  \n",
       "3     1479.840019  False  \n",
       "4     1506.577674  False  \n",
       "...           ...    ...  \n",
       "3056  1401.147746  False  \n",
       "3057  1400.849971  False  \n",
       "3058  1405.359836  False  \n",
       "3059  1412.263085  False  \n",
       "3060  1370.142915  False  \n",
       "\n",
       "[3061 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data['curva_direita_agressiva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont Run this part\n",
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "NUMBER_OF_TEST=100\n",
    "Model=dict()\n",
    "Report_of_Acc=dict()\n",
    "for name in Train_Data:\n",
    "    estimator = Id3Estimator(max_depth=3, min_samples_split=1, prune=True,\n",
    "                gain_ratio=True, min_entropy_decrease=0, is_repeating=True)\n",
    "    Data=Train_Data[name].drop('label',1)\n",
    "    label=Train_Data[name].label\n",
    "    temp=list()\n",
    "    for NT in range(NUMBER_OF_TEST):\n",
    "        estimator.fit(Data,label , check_input=True)\n",
    "        ACC=accuracy_score(y_true=label,y_pred=estimator.predict(Data))\n",
    "        temp.append((ACC,deepcopy(estimator)))\n",
    "    temp_index=[(x[0],i) for i,x in enumerate(temp)]\n",
    "    temp_index.sort()\n",
    "    print('Accuracy Score -',name,' : ',temp[temp_index[-1][1]][0])\n",
    "    estimator=temp[temp_index[-1][1]][1]\n",
    "    Model.update({name:deepcopy(estimator)})\n",
    "    Report_of_Acc.update({name:classification_report(label, estimator.predict(Data))})\n",
    "with open(\"Model.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Model, fp)\n",
    "with open(\"Report.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Report_of_Acc, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "with open(\"Model.txt\", \"rb\") as fp:\n",
    "    Model = pickle.load(fp)\n",
    "with open(\"Report.txt\", \"rb\") as fp:\n",
    "    Report_of_Acc = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99      3265\n",
      "        True       0.96      0.59      0.73       120\n",
      "\n",
      "    accuracy                           0.98      3385\n",
      "   macro avg       0.97      0.80      0.86      3385\n",
      "weighted avg       0.98      0.98      0.98      3385\n",
      "\n",
      "\n",
      "4 <=913.94: True (37) \n",
      "4 >913.94\n",
      "|   1 <=1353.63\n",
      "|   |   5 <=1048.73: True (3) \n",
      "|   |   5 >1048.73: False (2253/25) \n",
      "|   1 >1353.63\n",
      "|   |   6 <=1237.27: True (12) \n",
      "|   |   6 >1237.27: False (33/6) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator=Model['curva_direita_agressiva']\n",
    "print(Report_of_Acc['curva_direita_agressiva'])\n",
    "print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def export_tree_item(x):\n",
    "    x=export_text(estimator.tree_)\n",
    "    rep=re.compile(r'(\\d) >(\\d+.\\d+)')\n",
    "    mo=rep.findall(x)\n",
    "    return [(int(x1),float(x2)) for x1,x2 in mo]\n",
    "\n",
    "Model_param=dict()\n",
    "for name in Model.keys():\n",
    "    df=[x[1] for x in evented_label_All.groupby(0) if x[0] ==name ][0]\n",
    "    estimator=Model[name]\n",
    "    X=dict()\n",
    "    for dtree_eve , threshold in export_tree_item(export_text(estimator.tree_)) :\n",
    "        el=df.iloc[dtree_eve]\n",
    "        if   el[3]=='evented_label_1':\n",
    "            X.update({dtree_eve:(threshold,df1[el[1]:el[2]])})\n",
    "        elif el[3]=='evented_label_2':\n",
    "            X.update({dtree_eve:(threshold,df2[el[1]:el[2]])})\n",
    "        elif el[3]=='evented_label_3':\n",
    "            X.update({dtree_eve:(threshold,df3[el[1]:el[2]])})\n",
    "        elif el[3]=='evented_label_4':\n",
    "            X.update({dtree_eve:(threshold,df4[el[1]:el[2]])})\n",
    "    Model_param.update({name:X})\n",
    "\n",
    "with open(\"Model_param.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Model_param, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
