{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the name of god"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def color_map_color(value, cmap_name='coolwarm', vmin=0, vmax=10):\n",
    "    # norm = plt.Normalize(vmin, vmax)\n",
    "    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = cm.get_cmap(cmap_name)  # PiYG\n",
    "    rgb = cmap(norm(abs(value)))[:3]  # will return rgba, we take only first 3 so we get rgb\n",
    "    color = matplotlib.colors.rgb2hex(rgb)\n",
    "    return color\n",
    "cl=['r','g','b','c','m','y','k']\n",
    "color=dict()\n",
    "for i,el in enumerate(cl):\n",
    "    color.update({i:el})\n",
    "#extract the labels for clutering precision its for after clustering\n",
    "def time_convertor(x):\n",
    "    s,h,m=0,0,0\n",
    "    s=round(x%60,2)\n",
    "    m=int(x/60)\n",
    "    h=int(m/60)\n",
    "    m=m%60\n",
    "    time=str(h)+':'+str(m)+':'+str(s)\n",
    "    return pd.to_datetime('1970-01-01 '+time)\n",
    "\n",
    "\n",
    "# Display figures inline in Jupyter notebook\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(15, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_read\n",
    "def read_data(number):\n",
    "    #prepare Dataset gyroscope\n",
    "    dfg=pd.read_csv(f'{number}\\\\giroscopio_terra.csv')\n",
    "    dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "    dm=dfg['ts']\n",
    "    dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "    dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "    #prepare Dataset accelarator\n",
    "    dfa=pd.read_csv(f'{number}\\\\acelerometro_terra.csv')\n",
    "    dfa['ts']=dm\n",
    "    dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "    dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "    dfg['g-x']=dfg.apply(lambda x:(x[0]-min(dfg['g-x']))/(max(dfg['g-x'])-min(dfg['g-x'])),axis=1)\n",
    "    dfg['g-y']=dfg.apply(lambda x:(x[1]-min(dfg['g-y']))/(max(dfg['g-y'])-min(dfg['g-y'])),axis=1)\n",
    "    dfg['g-z']=dfg.apply(lambda x:(x[2]-min(dfg['g-z']))/(max(dfg['g-z'])-min(dfg['g-z'])),axis=1)\n",
    "    dfa['a-x']=dfa.apply(lambda x:(x[0]-min(dfa['a-x']))/(max(dfa['a-x'])-min(dfa['a-x'])),axis=1)\n",
    "    dfa['a-y']=dfa.apply(lambda x:(x[1]-min(dfa['a-y']))/(max(dfa['a-y'])-min(dfa['a-y'])),axis=1)\n",
    "    dfa['a-z']=dfa.apply(lambda x:(x[2]-min(dfa['a-z']))/(max(dfa['a-z'])-min(dfa['a-z'])),axis=1)\n",
    "    return pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "dfRaw=list()\n",
    "for num in [16,17,20,21]:\n",
    "    dfRaw.append((num,read_data(num)))\n",
    "with open(\"normalized_data.txt\", \"wb\") as fp:\n",
    "    pickle.dump(dfRaw, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"normalized_data.txt\", \"rb\") as fp:\n",
    "        dfRaw = pickle.load(fp)\n",
    "        \n",
    "def get_label(number,df):\n",
    "    label_event_lenght=dict()\n",
    "    df=pd.read_csv(f'{number}\\\\groundTruth.csv')\n",
    "    df['length']=df.en-df.st\n",
    "    for event , dft in df.groupby('evento'):\n",
    "        if (event in label_event_lenght):\n",
    "            label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "        else:\n",
    "            label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "    df['st_time']=df.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "    df['en_time']=df.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "    df=df.drop('st',1).drop('en',1).drop('length',1)\n",
    "    evented_label=list()\n",
    "    for i in range(len(df)):\n",
    "        evented_label.append((df.iloc[i][0],df.iloc[i][1],df.iloc[i][2]))\n",
    "    eve=pd.DataFrame(evented_label)\n",
    "    eve[3]=[f'evented_label_{number}' for x in evented_label]\n",
    "    return eve\n",
    "Ev=[get_label(dfRaw[x][0],dfRaw[x][1]) for x in range(len(dfRaw))]\n",
    "evented_label_All=pd.concat(Ev).reset_index().drop('index',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate is :0.02\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aceleracao_agressiva</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curva_direita_agressiva</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curva_esquerda_agressiva</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evento_nao_agressivo</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freada_agressiva</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troca_faixa_direita_agressiva</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troca_faixa_esquerda_agressiva</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  1\n",
       "0                                  \n",
       "aceleracao_agressiva            245\n",
       "curva_direita_agressiva         225\n",
       "curva_esquerda_agressiva        225\n",
       "evento_nao_agressivo            225\n",
       "freada_agressiva                185\n",
       "troca_faixa_direita_agressiva   125\n",
       "troca_faixa_esquerda_agressiva  120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=(dfRaw[0][1].index[11]-dfRaw[0][1].index[10]).total_seconds()\n",
    "\n",
    "print(f\"rate is :{rate}\")\n",
    "pd.DataFrame([(x[0],round(((x[2]-x[1]).total_seconds())/rate)) for x in evented_label_All.iloc]).groupby(0).agg({1:\"max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supervised\n",
    "window={226:['curva_direita_agressiva','curva_esquerda_agressiva','aceleracao_agressiva'],\n",
    "        126:['troca_faixa_direita_agressiva','troca_faixa_esquerda_agressiva'],\n",
    "        186:['freada_agressiva']\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction  1.0  % of  3  is complete\n"
     ]
    }
   ],
   "source": [
    "#Dont RUN this part\n",
    "#we should optimize M\n",
    "#lengh of random event\n",
    "import random\n",
    "random.seed(123)\n",
    "def TempEvent_genarator(df,L,i):\n",
    "    temp_event=list()\n",
    "    pointer=0\n",
    "    stop=False\n",
    "    #go on timeserise for event extraction\n",
    "    while stop!=True:\n",
    "        M=round(random.gauss(0.5,0.5)*L/2)\n",
    "        clear_output(wait=True)\n",
    "        pointer=pointer + M\n",
    "        l_min=pointer-int(L/2)\n",
    "        l_max=pointer+int(L/2)\n",
    "        if l_max<0:\n",
    "            l_max=L/2\n",
    "        if (l_min<0):\n",
    "            l_min=0\n",
    "        if (l_max>len(df)):\n",
    "            l_max=len(df)\n",
    "            stop=True\n",
    "        print('extraction ',l_max/len(df),' % of ',i,' is complete')\n",
    "        temp_event.append(df[int(l_min):int(l_max)])\n",
    "    return temp_event\n",
    "\n",
    "temp_event=list()\n",
    "for l,DF in enumerate([x[1] for x in dfRaw]):\n",
    "    te=list()\n",
    "    for i,lw in enumerate(window):\n",
    "        te.append((window[lw],TempEvent_genarator(DF,lw,i+1)))\n",
    "    temp_event.append(te)\n",
    "\n",
    "with open(\"temp_event_new.txt\", \"wb\") as fp:\n",
    "    pickle.dump(temp_event, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp_event_new.txt\", \"rb\") as fp:\n",
    "    temp_event = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_overlap(A_start, A_end, B_start, B_end):\n",
    "    latest_start = max(A_start, B_start)\n",
    "    earliest_end = min(A_end, B_end)\n",
    "    return latest_start <= earliest_end\n",
    "\n",
    "def export_labels(tempevent,evented_label):\n",
    "    EvL=pd.DataFrame(evented_label)\n",
    "    Labels={\n",
    "          226:[],\n",
    "          126:[],\n",
    "          186:[],\n",
    "           }\n",
    "    for i,wind in enumerate(Labels):\n",
    "        label=['NAG' for x in tempevent[i][1]]\n",
    "        for name in tempevent[i][0]:\n",
    "            el=[(x[1],x[2]) for x in EvL.iloc if x[0]==name]\n",
    "            for j,te in enumerate(tempevent[i][1]):\n",
    "                    sta =te.index[0]\n",
    "                    ena =te.index[-1]\n",
    "                    for stb,enb in el:\n",
    "                        if has_overlap(sta,ena,stb,enb):\n",
    "                            label[j]=name\n",
    "        Labels[wind]=label\n",
    "    return Labels\n",
    "\n",
    "\n",
    "Data={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "for i,temp in enumerate(temp_event):\n",
    "    TempEv={\n",
    "              226:[ x for x in temp_event[i][0][1] ],\n",
    "              126:[ x for x in temp_event[i][1][1] ],\n",
    "              186:[ x for x in temp_event[i][2][1] ],\n",
    "               }\n",
    "    Label=export_labels(temp_event[i],Ev[i])\n",
    "    #merge together\n",
    "    for wind in Data:\n",
    "        for j in range(len(TempEv[wind])):\n",
    "            Data[wind].append((Label[wind][j],TempEv[wind][j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NAG',\n",
       "                               a-x       a-y       a-z       g-x       g-y  \\\n",
       " ts                                                                          \n",
       " 1970-01-01 00:00:08.609  0.434717  0.495165  0.372532  0.584724  0.660125   \n",
       " 1970-01-01 00:00:08.629  0.434815  0.443337  0.369497  0.520917  0.743245   \n",
       " 1970-01-01 00:00:08.648  0.491156  0.511841  0.331410  0.485508  0.750034   \n",
       " 1970-01-01 00:00:08.668  0.529514  0.576479  0.332659  0.568974  0.723956   \n",
       " 1970-01-01 00:00:08.688  0.521595  0.473574  0.335476  0.589592  0.688791   \n",
       " ...                           ...       ...       ...       ...       ...   \n",
       " 1970-01-01 00:00:12.948  0.435919  0.445521  0.392083  0.541604  0.684052   \n",
       " 1970-01-01 00:00:12.968  0.443924  0.452585  0.371189  0.492296  0.726309   \n",
       " 1970-01-01 00:00:12.987  0.490837  0.511433  0.338475  0.513746  0.762484   \n",
       " 1970-01-01 00:00:13.007  0.503200  0.550687  0.326413  0.579276  0.666320   \n",
       " 1970-01-01 00:00:13.026  0.487606  0.501061  0.340951  0.619120  0.698186   \n",
       " \n",
       "                               g-z  \n",
       " ts                                 \n",
       " 1970-01-01 00:00:08.609  0.537795  \n",
       " 1970-01-01 00:00:08.629  0.514808  \n",
       " 1970-01-01 00:00:08.648  0.492242  \n",
       " 1970-01-01 00:00:08.668  0.515473  \n",
       " 1970-01-01 00:00:08.688  0.513416  \n",
       " ...                           ...  \n",
       " 1970-01-01 00:00:12.948  0.544407  \n",
       " 1970-01-01 00:00:12.968  0.504881  \n",
       " 1970-01-01 00:00:12.987  0.505905  \n",
       " 1970-01-01 00:00:13.007  0.516401  \n",
       " 1970-01-01 00:00:13.026  0.511026  \n",
       " \n",
       " [226 rows x 6 columns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[226][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  100.0  %  is complete\n",
      "210 min has time for calculaton distant\n"
     ]
    }
   ],
   "source": [
    "#dont run this part\n",
    "#calculate dist of Data from labdeled event\n",
    "t1=time.time()\n",
    "\n",
    "k,n=0,0\n",
    "num_event=dict(evented_label_All.groupby(0).size())\n",
    "for lenght in window:\n",
    "    for name in window[lenght]:\n",
    "        k=k+len(Data[lenght])*num_event[name]\n",
    "\n",
    "Data_DS={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wind in Data:\n",
    "    for label,event in Data[wind]:\n",
    "         #---------for each Data-distance from events----------\n",
    "        Y=list()\n",
    "        for from_event,dfe in evented_label_All.groupby(0):\n",
    "            if from_event in window[wind]:\n",
    "                X=list()\n",
    "                #____for each event_distance from each label_____\n",
    "                for el in dfe.iloc:\n",
    "                    clear_output(wait=True)\n",
    "                    n=n+1\n",
    "                    print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "                    if   el[3]=='evented_label_16':\n",
    "                        X.append(fastdtw(event,dfRaw[0][1][el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_17':\n",
    "                        X.append(fastdtw(event,dfRaw[1][1][el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_20':\n",
    "                        X.append(fastdtw(event,dfRaw[2][1][el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_21':\n",
    "                        X.append(fastdtw(event,dfRaw[3][1][el[1]:el[2]])[0])\n",
    "                #_________________________________________________\n",
    "                Y.append((from_event,X))\n",
    "        Data_DS[wind].append((label,Y))\n",
    "        #------------------------------------------------------\n",
    "\n",
    "t2=time.time()\n",
    "with open(\"Disstance_new.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Data_DS, fp)\n",
    "\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton distant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Disstance_new.txt\", \"rb\") as fp:\n",
    "    Data_DS = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NAG',\n",
       " [('aceleracao_agressiva',\n",
       "   [191.54451527900127,\n",
       "    196.38316303046787,\n",
       "    206.10318235888877,\n",
       "    190.36035998875744,\n",
       "    215.45851999560674,\n",
       "    201.6141655570143,\n",
       "    195.7536650022861,\n",
       "    211.49902944277997,\n",
       "    186.4721907691484,\n",
       "    192.15442188996943,\n",
       "    186.2779097408009,\n",
       "    189.36629647950832]),\n",
       "  ('curva_direita_agressiva',\n",
       "   [139.1863155699013,\n",
       "    134.0729931726308,\n",
       "    138.01092977305652,\n",
       "    138.33203932961524,\n",
       "    132.61000791284755,\n",
       "    195.92303721517737,\n",
       "    184.09107164297535,\n",
       "    188.88327881457244,\n",
       "    185.7430090706699,\n",
       "    200.07598574250963,\n",
       "    200.84831426313477]),\n",
       "  ('curva_esquerda_agressiva',\n",
       "   [141.5015798031517,\n",
       "    146.40583349086597,\n",
       "    141.23016066764876,\n",
       "    135.5944426447342,\n",
       "    135.0949140259224,\n",
       "    147.73807836029138,\n",
       "    147.57293721169253,\n",
       "    189.1883871648448,\n",
       "    182.55261910752938,\n",
       "    150.69019361607639,\n",
       "    143.56230971182543])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_DS[226][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataset for labeling\n",
    "TrainData=dict()\n",
    "for win in Data_DS:\n",
    "    x=Data_DS[win]\n",
    "    dumy_list=list()\n",
    "    for events in x:\n",
    "        dumy_dict=dict()\n",
    "        dumy_dict.update({'label':events[0]})\n",
    "        for name , event in events[1]:\n",
    "            for tag,number in enumerate(event):\n",
    "                dumy_dict.update({name+str(tag):number})\n",
    "        dumy_list.append(dumy_dict)\n",
    "    TrainData.update({win:pd.DataFrame(dumy_list)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>aceleracao_agressiva0</th>\n",
       "      <th>aceleracao_agressiva1</th>\n",
       "      <th>aceleracao_agressiva2</th>\n",
       "      <th>aceleracao_agressiva3</th>\n",
       "      <th>aceleracao_agressiva4</th>\n",
       "      <th>aceleracao_agressiva5</th>\n",
       "      <th>aceleracao_agressiva6</th>\n",
       "      <th>aceleracao_agressiva7</th>\n",
       "      <th>aceleracao_agressiva8</th>\n",
       "      <th>...</th>\n",
       "      <th>curva_esquerda_agressiva1</th>\n",
       "      <th>curva_esquerda_agressiva2</th>\n",
       "      <th>curva_esquerda_agressiva3</th>\n",
       "      <th>curva_esquerda_agressiva4</th>\n",
       "      <th>curva_esquerda_agressiva5</th>\n",
       "      <th>curva_esquerda_agressiva6</th>\n",
       "      <th>curva_esquerda_agressiva7</th>\n",
       "      <th>curva_esquerda_agressiva8</th>\n",
       "      <th>curva_esquerda_agressiva9</th>\n",
       "      <th>curva_esquerda_agressiva10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAG</td>\n",
       "      <td>152.197999</td>\n",
       "      <td>160.497296</td>\n",
       "      <td>186.592491</td>\n",
       "      <td>165.302999</td>\n",
       "      <td>210.106082</td>\n",
       "      <td>196.125649</td>\n",
       "      <td>173.099501</td>\n",
       "      <td>214.405838</td>\n",
       "      <td>162.520954</td>\n",
       "      <td>...</td>\n",
       "      <td>134.069696</td>\n",
       "      <td>130.659010</td>\n",
       "      <td>127.619507</td>\n",
       "      <td>125.083264</td>\n",
       "      <td>136.117751</td>\n",
       "      <td>119.478497</td>\n",
       "      <td>169.938228</td>\n",
       "      <td>169.936294</td>\n",
       "      <td>131.389872</td>\n",
       "      <td>117.843499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NAG</td>\n",
       "      <td>174.132673</td>\n",
       "      <td>186.612654</td>\n",
       "      <td>195.795481</td>\n",
       "      <td>181.111607</td>\n",
       "      <td>209.379603</td>\n",
       "      <td>195.172057</td>\n",
       "      <td>196.726296</td>\n",
       "      <td>214.388954</td>\n",
       "      <td>186.094920</td>\n",
       "      <td>...</td>\n",
       "      <td>137.802186</td>\n",
       "      <td>130.092994</td>\n",
       "      <td>128.639639</td>\n",
       "      <td>125.737518</td>\n",
       "      <td>147.348257</td>\n",
       "      <td>135.079695</td>\n",
       "      <td>184.270782</td>\n",
       "      <td>177.154381</td>\n",
       "      <td>150.860153</td>\n",
       "      <td>138.053369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAG</td>\n",
       "      <td>180.011335</td>\n",
       "      <td>190.334389</td>\n",
       "      <td>198.662247</td>\n",
       "      <td>178.965790</td>\n",
       "      <td>207.663424</td>\n",
       "      <td>195.148659</td>\n",
       "      <td>195.247498</td>\n",
       "      <td>212.591710</td>\n",
       "      <td>184.101841</td>\n",
       "      <td>...</td>\n",
       "      <td>139.716997</td>\n",
       "      <td>130.120482</td>\n",
       "      <td>129.099205</td>\n",
       "      <td>127.764363</td>\n",
       "      <td>148.583594</td>\n",
       "      <td>141.254033</td>\n",
       "      <td>183.945023</td>\n",
       "      <td>175.007803</td>\n",
       "      <td>149.724870</td>\n",
       "      <td>142.797234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NAG</td>\n",
       "      <td>187.901446</td>\n",
       "      <td>197.688761</td>\n",
       "      <td>204.792589</td>\n",
       "      <td>183.060550</td>\n",
       "      <td>209.385808</td>\n",
       "      <td>194.333629</td>\n",
       "      <td>191.702616</td>\n",
       "      <td>208.909757</td>\n",
       "      <td>181.404671</td>\n",
       "      <td>...</td>\n",
       "      <td>146.508009</td>\n",
       "      <td>136.767687</td>\n",
       "      <td>132.158555</td>\n",
       "      <td>133.325194</td>\n",
       "      <td>145.808301</td>\n",
       "      <td>148.953552</td>\n",
       "      <td>188.733119</td>\n",
       "      <td>176.193748</td>\n",
       "      <td>145.361263</td>\n",
       "      <td>143.916225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAG</td>\n",
       "      <td>189.349957</td>\n",
       "      <td>195.899470</td>\n",
       "      <td>205.721027</td>\n",
       "      <td>188.775423</td>\n",
       "      <td>215.416464</td>\n",
       "      <td>202.042344</td>\n",
       "      <td>189.722289</td>\n",
       "      <td>206.523534</td>\n",
       "      <td>180.485032</td>\n",
       "      <td>...</td>\n",
       "      <td>141.166271</td>\n",
       "      <td>141.219495</td>\n",
       "      <td>131.388284</td>\n",
       "      <td>131.289693</td>\n",
       "      <td>144.321050</td>\n",
       "      <td>144.376773</td>\n",
       "      <td>186.616092</td>\n",
       "      <td>179.565794</td>\n",
       "      <td>144.596604</td>\n",
       "      <td>140.896358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NAG</td>\n",
       "      <td>187.384897</td>\n",
       "      <td>194.009647</td>\n",
       "      <td>207.124083</td>\n",
       "      <td>190.775561</td>\n",
       "      <td>215.979745</td>\n",
       "      <td>202.112077</td>\n",
       "      <td>191.874606</td>\n",
       "      <td>208.281975</td>\n",
       "      <td>182.014288</td>\n",
       "      <td>...</td>\n",
       "      <td>141.376081</td>\n",
       "      <td>137.099474</td>\n",
       "      <td>134.377320</td>\n",
       "      <td>132.532075</td>\n",
       "      <td>147.059851</td>\n",
       "      <td>141.723150</td>\n",
       "      <td>187.675786</td>\n",
       "      <td>181.846478</td>\n",
       "      <td>147.281289</td>\n",
       "      <td>139.569838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAG</td>\n",
       "      <td>188.813968</td>\n",
       "      <td>195.058204</td>\n",
       "      <td>206.458820</td>\n",
       "      <td>190.177843</td>\n",
       "      <td>216.031373</td>\n",
       "      <td>202.839420</td>\n",
       "      <td>192.046547</td>\n",
       "      <td>208.498959</td>\n",
       "      <td>181.821516</td>\n",
       "      <td>...</td>\n",
       "      <td>140.771136</td>\n",
       "      <td>137.749359</td>\n",
       "      <td>133.784181</td>\n",
       "      <td>133.603994</td>\n",
       "      <td>147.262097</td>\n",
       "      <td>141.119745</td>\n",
       "      <td>187.429157</td>\n",
       "      <td>181.148182</td>\n",
       "      <td>148.028778</td>\n",
       "      <td>139.236481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NAG</td>\n",
       "      <td>187.994730</td>\n",
       "      <td>194.484463</td>\n",
       "      <td>205.107036</td>\n",
       "      <td>190.266882</td>\n",
       "      <td>215.539398</td>\n",
       "      <td>201.263330</td>\n",
       "      <td>194.631856</td>\n",
       "      <td>211.023260</td>\n",
       "      <td>185.166637</td>\n",
       "      <td>...</td>\n",
       "      <td>145.201152</td>\n",
       "      <td>139.747416</td>\n",
       "      <td>138.259912</td>\n",
       "      <td>138.498218</td>\n",
       "      <td>147.851698</td>\n",
       "      <td>143.489794</td>\n",
       "      <td>190.351302</td>\n",
       "      <td>183.353196</td>\n",
       "      <td>149.954194</td>\n",
       "      <td>140.850625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NAG</td>\n",
       "      <td>189.131907</td>\n",
       "      <td>194.796002</td>\n",
       "      <td>204.503946</td>\n",
       "      <td>188.761881</td>\n",
       "      <td>213.573636</td>\n",
       "      <td>200.159248</td>\n",
       "      <td>195.048884</td>\n",
       "      <td>210.132569</td>\n",
       "      <td>186.618618</td>\n",
       "      <td>...</td>\n",
       "      <td>145.030567</td>\n",
       "      <td>138.186932</td>\n",
       "      <td>135.035726</td>\n",
       "      <td>134.092135</td>\n",
       "      <td>148.265918</td>\n",
       "      <td>146.585596</td>\n",
       "      <td>188.933583</td>\n",
       "      <td>180.947428</td>\n",
       "      <td>150.665747</td>\n",
       "      <td>141.113163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NAG</td>\n",
       "      <td>190.102388</td>\n",
       "      <td>196.620819</td>\n",
       "      <td>206.544598</td>\n",
       "      <td>189.718784</td>\n",
       "      <td>214.251714</td>\n",
       "      <td>201.285006</td>\n",
       "      <td>195.607015</td>\n",
       "      <td>211.565676</td>\n",
       "      <td>187.697392</td>\n",
       "      <td>...</td>\n",
       "      <td>146.620132</td>\n",
       "      <td>139.287957</td>\n",
       "      <td>135.881675</td>\n",
       "      <td>137.095633</td>\n",
       "      <td>149.328110</td>\n",
       "      <td>146.931399</td>\n",
       "      <td>189.254757</td>\n",
       "      <td>181.720578</td>\n",
       "      <td>152.030709</td>\n",
       "      <td>144.604059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  aceleracao_agressiva0  aceleracao_agressiva1  aceleracao_agressiva2  \\\n",
       "0   NAG             152.197999             160.497296             186.592491   \n",
       "1   NAG             174.132673             186.612654             195.795481   \n",
       "2   NAG             180.011335             190.334389             198.662247   \n",
       "3   NAG             187.901446             197.688761             204.792589   \n",
       "4   NAG             189.349957             195.899470             205.721027   \n",
       "5   NAG             187.384897             194.009647             207.124083   \n",
       "6   NAG             188.813968             195.058204             206.458820   \n",
       "7   NAG             187.994730             194.484463             205.107036   \n",
       "8   NAG             189.131907             194.796002             204.503946   \n",
       "9   NAG             190.102388             196.620819             206.544598   \n",
       "\n",
       "   aceleracao_agressiva3  aceleracao_agressiva4  aceleracao_agressiva5  \\\n",
       "0             165.302999             210.106082             196.125649   \n",
       "1             181.111607             209.379603             195.172057   \n",
       "2             178.965790             207.663424             195.148659   \n",
       "3             183.060550             209.385808             194.333629   \n",
       "4             188.775423             215.416464             202.042344   \n",
       "5             190.775561             215.979745             202.112077   \n",
       "6             190.177843             216.031373             202.839420   \n",
       "7             190.266882             215.539398             201.263330   \n",
       "8             188.761881             213.573636             200.159248   \n",
       "9             189.718784             214.251714             201.285006   \n",
       "\n",
       "   aceleracao_agressiva6  aceleracao_agressiva7  aceleracao_agressiva8  ...  \\\n",
       "0             173.099501             214.405838             162.520954  ...   \n",
       "1             196.726296             214.388954             186.094920  ...   \n",
       "2             195.247498             212.591710             184.101841  ...   \n",
       "3             191.702616             208.909757             181.404671  ...   \n",
       "4             189.722289             206.523534             180.485032  ...   \n",
       "5             191.874606             208.281975             182.014288  ...   \n",
       "6             192.046547             208.498959             181.821516  ...   \n",
       "7             194.631856             211.023260             185.166637  ...   \n",
       "8             195.048884             210.132569             186.618618  ...   \n",
       "9             195.607015             211.565676             187.697392  ...   \n",
       "\n",
       "   curva_esquerda_agressiva1  curva_esquerda_agressiva2  \\\n",
       "0                 134.069696                 130.659010   \n",
       "1                 137.802186                 130.092994   \n",
       "2                 139.716997                 130.120482   \n",
       "3                 146.508009                 136.767687   \n",
       "4                 141.166271                 141.219495   \n",
       "5                 141.376081                 137.099474   \n",
       "6                 140.771136                 137.749359   \n",
       "7                 145.201152                 139.747416   \n",
       "8                 145.030567                 138.186932   \n",
       "9                 146.620132                 139.287957   \n",
       "\n",
       "   curva_esquerda_agressiva3  curva_esquerda_agressiva4  \\\n",
       "0                 127.619507                 125.083264   \n",
       "1                 128.639639                 125.737518   \n",
       "2                 129.099205                 127.764363   \n",
       "3                 132.158555                 133.325194   \n",
       "4                 131.388284                 131.289693   \n",
       "5                 134.377320                 132.532075   \n",
       "6                 133.784181                 133.603994   \n",
       "7                 138.259912                 138.498218   \n",
       "8                 135.035726                 134.092135   \n",
       "9                 135.881675                 137.095633   \n",
       "\n",
       "   curva_esquerda_agressiva5  curva_esquerda_agressiva6  \\\n",
       "0                 136.117751                 119.478497   \n",
       "1                 147.348257                 135.079695   \n",
       "2                 148.583594                 141.254033   \n",
       "3                 145.808301                 148.953552   \n",
       "4                 144.321050                 144.376773   \n",
       "5                 147.059851                 141.723150   \n",
       "6                 147.262097                 141.119745   \n",
       "7                 147.851698                 143.489794   \n",
       "8                 148.265918                 146.585596   \n",
       "9                 149.328110                 146.931399   \n",
       "\n",
       "   curva_esquerda_agressiva7  curva_esquerda_agressiva8  \\\n",
       "0                 169.938228                 169.936294   \n",
       "1                 184.270782                 177.154381   \n",
       "2                 183.945023                 175.007803   \n",
       "3                 188.733119                 176.193748   \n",
       "4                 186.616092                 179.565794   \n",
       "5                 187.675786                 181.846478   \n",
       "6                 187.429157                 181.148182   \n",
       "7                 190.351302                 183.353196   \n",
       "8                 188.933583                 180.947428   \n",
       "9                 189.254757                 181.720578   \n",
       "\n",
       "   curva_esquerda_agressiva9  curva_esquerda_agressiva10  \n",
       "0                 131.389872                  117.843499  \n",
       "1                 150.860153                  138.053369  \n",
       "2                 149.724870                  142.797234  \n",
       "3                 145.361263                  143.916225  \n",
       "4                 144.596604                  140.896358  \n",
       "5                 147.281289                  139.569838  \n",
       "6                 148.028778                  139.236481  \n",
       "7                 149.954194                  140.850625  \n",
       "8                 150.665747                  141.113163  \n",
       "9                 152.030709                  144.604059  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData[226].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize Train Data\n",
    "#Balance it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  300.0  %  is complete\n",
      "356 min has time for calculaton Model\n"
     ]
    }
   ],
   "source": [
    "#dont run this part\n",
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "t1=time.time()\n",
    "n,k=0,12*50\n",
    "\n",
    "Result={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wid in Result:\n",
    "    data=TrainData[wid].drop('label',1)\n",
    "    label=TrainData[wid].label\n",
    "    #\n",
    "    for Max_depth in range(1,13):\n",
    "        estimator = Id3Estimator(max_depth=Max_depth, min_samples_split=1, prune=True,\n",
    "                        gain_ratio=True, min_entropy_decrease=0, is_repeating=True)\n",
    "        #run it in itaraion for the best trees\n",
    "        NUMBER_OF_TEST=50\n",
    "        temp=list()\n",
    "        for NT in range(NUMBER_OF_TEST):\n",
    "            clear_output(wait=True)\n",
    "            n=n+1\n",
    "            print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "            estimator.fit(data,label , check_input=True)\n",
    "            ACC=accuracy_score(y_true=label,y_pred=estimator.predict(data))\n",
    "            temp.append((ACC,deepcopy(estimator)))\n",
    "        temp_index=[(x[0],i) for i,x in enumerate(temp)]\n",
    "        temp_index.sort()\n",
    "        Acc=temp[temp_index[-1][1]][0]\n",
    "        estimator=temp[temp_index[-1][1]][1]\n",
    "        Result[wid].append((Acc,deepcopy(estimator)))\n",
    "\n",
    "with open(\"Model_new_1.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Result, fp)\n",
    "t2=time.time()\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "with open(\"Model_new_1.txt\", \"rb\") as fp:\n",
    "    Result = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9927609089081038\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                           NAG       0.99      1.00      1.00      4896\n",
      " troca_faixa_direita_agressiva       0.96      0.59      0.73        46\n",
      "troca_faixa_esquerda_agressiva       0.78      0.68      0.72        31\n",
      "\n",
      "                      accuracy                           0.99      4973\n",
      "                     macro avg       0.91      0.75      0.82      4973\n",
      "                  weighted avg       0.99      0.99      0.99      4973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=7\n",
    "wid=126\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888721804511278\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "             NAG       0.99      1.00      0.99      3234\n",
      "freada_agressiva       0.90      0.67      0.77        91\n",
      "\n",
      "        accuracy                           0.99      3325\n",
      "       macro avg       0.94      0.83      0.88      3325\n",
      "    weighted avg       0.99      0.99      0.99      3325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=7\n",
    "wid=186\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9534528805799313\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                     NAG       0.95      1.00      0.97      2379\n",
      "    aceleracao_agressiva       0.96      0.27      0.42        81\n",
      " curva_direita_agressiva       1.00      0.52      0.68        62\n",
      "curva_esquerda_agressiva       0.99      0.69      0.81        99\n",
      "\n",
      "                accuracy                           0.95      2621\n",
      "               macro avg       0.97      0.62      0.72      2621\n",
      "            weighted avg       0.95      0.95      0.94      2621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=7\n",
    "wid=226\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overfit model!\n",
    "Overfit_model={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wid in Overfit_model:\n",
    "    data=TrainData[wid].drop('label',1)\n",
    "    label=TrainData[wid].label\n",
    "    #\n",
    "    estimator = Id3Estimator(max_depth=100, min_samples_split=1, prune=True,\n",
    "                    gain_ratio=True, min_entropy_decrease=0, is_repeating=True)\n",
    "    #run it in itaraion for the best trees\n",
    "    NUMBER_OF_TEST=10\n",
    "    temp=list()\n",
    "    for NT in range(NUMBER_OF_TEST):\n",
    "        estimator.fit(data,label , check_input=True)\n",
    "        ACC=accuracy_score(y_true=label,y_pred=estimator.predict(data))\n",
    "        temp.append((ACC,deepcopy(estimator)))\n",
    "    temp_index=[(x[0],i) for i,x in enumerate(temp)]\n",
    "    temp_index.sort()\n",
    "    Acc=temp[temp_index[-1][1]][0]\n",
    "    estimator=temp[temp_index[-1][1]][1]\n",
    "    Overfit_model[wid]=(Acc,deepcopy(estimator))\n",
    "\n",
    "with open(\"TrainData_test_l_1.txt\", \"wb\") as fp:\n",
    "    pickle.dump((Overfit_model), fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wid=226\n",
    "data=TrainData[wid].drop('label',1)\n",
    "label=TrainData[wid].label\n",
    "print(classification_report(label, Overfit_model[wid][1].predict(data)))\n",
    "#its completely ovefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in wid window:\n",
    "    estimator=Result[wid][5][1]\n",
    "    x={x for x in estimator.predict(Test_new[wid])}\n",
    "    print(f\" {wid} is : {x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "x=data.columns[30]\n",
    "rep=re.compile(r'(\\w+)(\\d+)')\n",
    "mo=rep.findall(x)[0]\n",
    "print(mo[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot charts for find the optimom\n",
    "Y1=[x[0]for x in Result[226]]\n",
    "Y2=[x[0]for x in Result[186]]\n",
    "Y3=[x[0]for x in Result[126]]\n",
    "\n",
    "X=range(1,11)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(X,Y1, linestyle='-', linewidth=2,c='r')\n",
    "ax.plot(X,Y2, linestyle='-', linewidth=2,c='g')\n",
    "ax.plot(X,Y3, linestyle='-', linewidth=2,c='b')\n",
    "\n",
    "ax.legend();\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
