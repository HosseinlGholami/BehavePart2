{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the name of god"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def color_map_color(value, cmap_name='coolwarm', vmin=0, vmax=10):\n",
    "    # norm = plt.Normalize(vmin, vmax)\n",
    "    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = cm.get_cmap(cmap_name)  # PiYG\n",
    "    rgb = cmap(norm(abs(value)))[:3]  # will return rgba, we take only first 3 so we get rgb\n",
    "    color = matplotlib.colors.rgb2hex(rgb)\n",
    "    return color\n",
    "cl=['r','g','b','c','m','y','k']\n",
    "color=dict()\n",
    "for i,el in enumerate(cl):\n",
    "    color.update({i:el})\n",
    "#extract the labels for clutering precision its for after clustering\n",
    "def time_convertor(x):\n",
    "    s,h,m=0,0,0\n",
    "    s=round(x%60,2)\n",
    "    m=int(x/60)\n",
    "    h=int(m/60)\n",
    "    m=m%60\n",
    "    time=str(h)+':'+str(m)+':'+str(s)\n",
    "    return pd.to_datetime('1970-01-01 '+time)\n",
    "\n",
    "\n",
    "# Display figures inline in Jupyter notebook\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(15, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_read\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('16\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('16\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "dfg['g-x']=dfg.apply(lambda x:x[0]/max(dfg['g-x']),axis=1)\n",
    "dfg['g-y']=dfg.apply(lambda x:x[1]/max(dfg['g-y']),axis=1)\n",
    "dfg['g-z']=dfg.apply(lambda x:x[2]/max(dfg['g-z']),axis=1)\n",
    "dfa['a-x']=dfg.apply(lambda x:x[0]/max(dfa['a-x']),axis=1)\n",
    "dfa['a-y']=dfg.apply(lambda x:x[1]/max(dfa['a-y']),axis=1)\n",
    "dfa['a-z']=dfg.apply(lambda x:x[2]/max(dfa['a-z']),axis=1)\n",
    "df1 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('17\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('17\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "dfg['g-x']=dfg.apply(lambda x:x[0]/max(dfg['g-x']),axis=1)\n",
    "dfg['g-y']=dfg.apply(lambda x:x[1]/max(dfg['g-y']),axis=1)\n",
    "dfg['g-z']=dfg.apply(lambda x:x[2]/max(dfg['g-z']),axis=1)\n",
    "dfa['a-x']=dfg.apply(lambda x:x[0]/max(dfa['a-x']),axis=1)\n",
    "dfa['a-y']=dfg.apply(lambda x:x[1]/max(dfa['a-y']),axis=1)\n",
    "dfa['a-z']=dfg.apply(lambda x:x[2]/max(dfa['a-z']),axis=1)\n",
    "df2 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('20\\\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('20\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "dfg['g-x']=dfg.apply(lambda x:x[0]/max(dfg['g-x']),axis=1)\n",
    "dfg['g-y']=dfg.apply(lambda x:x[1]/max(dfg['g-y']),axis=1)\n",
    "dfg['g-z']=dfg.apply(lambda x:x[2]/max(dfg['g-z']),axis=1)\n",
    "dfa['a-x']=dfg.apply(lambda x:x[0]/max(dfa['a-x']),axis=1)\n",
    "dfa['a-y']=dfg.apply(lambda x:x[1]/max(dfa['a-y']),axis=1)\n",
    "dfa['a-z']=dfg.apply(lambda x:x[2]/max(dfa['a-z']),axis=1)\n",
    "df3 = pd.concat([dfa, dfg], axis=1, join='outer')\n",
    "#prepare Dataset gyroscope\n",
    "dfg=pd.read_csv('21\\giroscopio_terra.csv')\n",
    "dfg['ts']=pd.to_datetime(dfg.apply(lambda x:(round((x.uptimeNanos-dfg.uptimeNanos[0])/1000000)*1000000),axis=1))\n",
    "dm=dfg['ts']\n",
    "dfg=dfg.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfg=dfg.set_index('ts').rename(columns={'x': 'g-x','y': 'g-y','z': 'g-z'})\n",
    "#prepare Dataset accelarator\n",
    "dfa=pd.read_csv('21\\\\acelerometro_terra.csv')\n",
    "dfa['ts']=dm\n",
    "dfa=dfa.drop('uptimeNanos',1).drop('timestamp',1)\n",
    "dfa=dfa.set_index('ts').rename(columns={'x': 'a-x','y': 'a-y','z': 'a-z'})\n",
    "dfg['g-x']=dfg.apply(lambda x:x[0]/max(dfg['g-x']),axis=1)\n",
    "dfg['g-y']=dfg.apply(lambda x:x[1]/max(dfg['g-y']),axis=1)\n",
    "dfg['g-z']=dfg.apply(lambda x:x[2]/max(dfg['g-z']),axis=1)\n",
    "dfa['a-x']=dfg.apply(lambda x:x[0]/max(dfa['a-x']),axis=1)\n",
    "dfa['a-y']=dfg.apply(lambda x:x[1]/max(dfa['a-y']),axis=1)\n",
    "dfa['a-z']=dfg.apply(lambda x:x[2]/max(dfa['a-z']),axis=1)\n",
    "df4 = pd.concat([dfa, dfg], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_event_lenght=dict()\n",
    "#prepare Labeled dataset on 16\n",
    "dfl=pd.read_csv('16\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "        \n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_1=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_1.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 17\n",
    "dfl=pd.read_csv('17\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_2=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_2.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 20\n",
    "dfl=pd.read_csv('20\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_3=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_3.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))\n",
    "#prepare Labeled dataset on 21\n",
    "dfl=pd.read_csv('21\\\\groundTruth.csv')\n",
    "dfl['length']=dfl.en-dfl.st\n",
    "for event , dft in dfl.groupby('evento'):\n",
    "    if (event in label_event_lenght):\n",
    "        label_event_lenght.update({event : label_event_lenght[event]+list(dft.length) })\n",
    "    else:\n",
    "        label_event_lenght.update({event : list(dft.length)})\n",
    "dfl['st_time']=dfl.apply(lambda x:time_convertor(x.st) ,axis=1 )\n",
    "dfl['en_time']=dfl.apply(lambda x:time_convertor(x.en) ,axis=1 )\n",
    "dfl=dfl.drop('st',1).drop('en',1).drop('length',1)\n",
    "evented_label_4=list()\n",
    "for i in range(len(dfl)):\n",
    "    evented_label_4.append((dfl.iloc[i][0],dfl.iloc[i][1],dfl.iloc[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve1=pd.DataFrame(evented_label_1)\n",
    "eve1[3]=['evented_label_1' for x in evented_label_1]\n",
    "\n",
    "eve2=pd.DataFrame(evented_label_2)\n",
    "eve2[3]=['evented_label_2' for x in evented_label_2]\n",
    "\n",
    "eve3=pd.DataFrame(evented_label_3)\n",
    "eve3[3]=['evented_label_3' for x in evented_label_3]\n",
    "\n",
    "eve4=pd.DataFrame(evented_label_4)\n",
    "eve4[3]=['evented_label_4' for x in evented_label_4]\n",
    "\n",
    "evented_label_All=pd.concat([eve1, eve2,eve3,eve4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate is :0.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('curva_direita_agressiva', 225),\n",
       " ('curva_esquerda_agressiva', 225),\n",
       " ('evento_nao_agressivo', 225),\n",
       " ('troca_faixa_direita_agressiva', 125),\n",
       " ('aceleracao_agressiva', 245),\n",
       " ('freada_agressiva', 185),\n",
       " ('troca_faixa_esquerda_agressiva', 120)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=(df2.index[6]-df3.index[5]).total_seconds()\n",
    "window_list=list()\n",
    "for event in label_event_lenght:\n",
    "    window_list.append((event,round(max(label_event_lenght[event])/rate)))\n",
    "print(f\"rate is :{rate}\")\n",
    "window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supervised\n",
    "window={226:['curva_direita_agressiva','curva_esquerda_agressiva','aceleracao_agressiva'],\n",
    "        126:['troca_faixa_direita_agressiva','troca_faixa_esquerda_agressiva'],\n",
    "        186:['freada_agressiva']\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction  1.0  % of  3  is complete\n"
     ]
    }
   ],
   "source": [
    "#Dont RUN this part\n",
    "#we should optimize M\n",
    "#lengh of random event\n",
    "import random\n",
    "random.seed(123)\n",
    "def TempEvent_genarator(df,L,i):\n",
    "    M=round(random.gauss(0.2,0.5)*L/2)\n",
    "    temp_event=list()\n",
    "    pointer=0\n",
    "    stop=False\n",
    "    #go on timeserise for event extraction\n",
    "    while stop!=True:\n",
    "        clear_output(wait=True)\n",
    "        pointer=pointer + M\n",
    "        l_min=pointer-int(L/2)\n",
    "        l_max=pointer+int(L/2)\n",
    "        if l_max<0:\n",
    "            l_max=L/2\n",
    "        if (l_min<0):\n",
    "            l_min=0\n",
    "        if (l_max>len(df)):\n",
    "            l_max=len(df)\n",
    "            stop=True\n",
    "        print('extraction ',l_max/len(df),' % of ',i,' is complete')\n",
    "        temp_event.append(df[l_min:l_max])\n",
    "    return temp_event\n",
    "\n",
    "temp_event=list()\n",
    "for l,DF in enumerate([df1,df2,df3,df4]):\n",
    "    te=list()\n",
    "    for i,lw in enumerate(window):\n",
    "        te.append((window[lw],TempEvent_genarator(DF,lw,i+1)))\n",
    "    temp_event.append(te)\n",
    "\n",
    "with open(\"temp_event_new.txt\", \"wb\") as fp:\n",
    "    pickle.dump(temp_event, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp_event_new.txt\", \"rb\") as fp:\n",
    "    temp_event = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_overlap(A_start, A_end, B_start, B_end):\n",
    "    latest_start = max(A_start, B_start)\n",
    "    earliest_end = min(A_end, B_end)\n",
    "    return latest_start <= earliest_end\n",
    "\n",
    "def export_labels(tempevent,evented_label):\n",
    "    EvL=pd.DataFrame(evented_label)\n",
    "    Labels={\n",
    "          226:[],\n",
    "          126:[],\n",
    "          186:[],\n",
    "           }\n",
    "    for i,wind in enumerate(Labels):\n",
    "        label=['NAG' for x in tempevent[i][1]]\n",
    "        for name in tempevent[i][0]:\n",
    "            el=[(x[1],x[2]) for x in EvL.iloc if x[0]==name]\n",
    "            for j,te in enumerate(tempevent[i][1]):\n",
    "                    sta =te.index[0]\n",
    "                    ena =te.index[-1]\n",
    "                    for stb,enb in el:\n",
    "                        if has_overlap(sta,ena,stb,enb):\n",
    "                            label[j]=name\n",
    "        Labels[wind]=label\n",
    "    return Labels\n",
    "\n",
    "Ev=[evented_label_1,evented_label_2,evented_label_3,evented_label_4]\n",
    "Data={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "for i,temp in enumerate(temp_event):\n",
    "    TempEv={\n",
    "              226:[ x for x in temp_event[i][0][1] ],\n",
    "              126:[ x for x in temp_event[i][1][1] ],\n",
    "              186:[ x for x in temp_event[i][2][1] ],\n",
    "               }\n",
    "    Label=export_labels(temp_event[i],Ev[i])\n",
    "    #merge together\n",
    "    for wind in Data:\n",
    "        for j in range(len(TempEv[wind])):\n",
    "            Data[wind].append((Label[wind][j],TempEv[wind][j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('curva_direita_agressiva',\n",
       "                               a-x       a-y       a-z       g-x       g-y  \\\n",
       " ts                                                                          \n",
       " 1970-01-01 00:00:17.424 -0.002093 -0.021755  0.010382 -0.015417 -0.137767   \n",
       " 1970-01-01 00:00:17.444 -0.007157 -0.087000  0.006271 -0.052717 -0.550952   \n",
       " 1970-01-01 00:00:17.463 -0.008427 -0.011405  0.000439 -0.062072 -0.072225   \n",
       " 1970-01-01 00:00:17.483  0.001180  0.039295 -0.007932  0.008689  0.248851   \n",
       " 1970-01-01 00:00:17.503  0.001611  0.047547 -0.010585  0.011868  0.301107   \n",
       " ...                           ...       ...       ...       ...       ...   \n",
       " 1970-01-01 00:00:21.763  0.007606 -0.013055 -0.029884  0.056029 -0.082675   \n",
       " 1970-01-01 00:00:21.783  0.009608 -0.014612 -0.026550  0.070771 -0.092535   \n",
       " 1970-01-01 00:00:21.803  0.070773 -0.044229 -0.027168  0.521318 -0.280091   \n",
       " 1970-01-01 00:00:21.822  0.068668 -0.032336 -0.030153  0.505813 -0.204778   \n",
       " 1970-01-01 00:00:21.842  0.042154 -0.015497 -0.031440  0.310508 -0.098139   \n",
       " \n",
       "                               g-z  \n",
       " ts                                 \n",
       " 1970-01-01 00:00:17.424  0.208808  \n",
       " 1970-01-01 00:00:17.444  0.126119  \n",
       " 1970-01-01 00:00:17.463  0.008824  \n",
       " 1970-01-01 00:00:17.483 -0.159542  \n",
       " 1970-01-01 00:00:17.503 -0.212894  \n",
       " ...                           ...  \n",
       " 1970-01-01 00:00:21.763 -0.601062  \n",
       " 1970-01-01 00:00:21.783 -0.534003  \n",
       " 1970-01-01 00:00:21.803 -0.546434  \n",
       " 1970-01-01 00:00:21.822 -0.606476  \n",
       " 1970-01-01 00:00:21.842 -0.632363  \n",
       " \n",
       " [226 rows x 6 columns])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[226][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  100.0  %  is complete\n",
      "211 min has time for calculaton distant\n"
     ]
    }
   ],
   "source": [
    "#dont run this part\n",
    "#calculate dist of Data from labdeled event\n",
    "t1=time.time()\n",
    "\n",
    "k,n=0,0\n",
    "num_event=dict(evented_label_All.groupby(0).size())\n",
    "for lenght in window:\n",
    "    for name in window[lenght]:\n",
    "        k=k+len(Data[lenght])*num_event[name]\n",
    "\n",
    "Data_DS={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wind in Data:\n",
    "    for label,event in Data[wind]:\n",
    "         #---------for each Data-distance from events----------\n",
    "        Y=list()\n",
    "        for from_event,dfe in evented_label_All.groupby(0):\n",
    "            if from_event in window[wind]:\n",
    "                X=list()\n",
    "                #____for each event_distance from each label_____\n",
    "                for el in dfe.iloc:\n",
    "                    clear_output(wait=True)\n",
    "                    n=n+1\n",
    "                    print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "                    if   el[3]=='evented_label_1':\n",
    "                        X.append(fastdtw(event,df1[el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_2':\n",
    "                        X.append(fastdtw(event,df2[el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_3':\n",
    "                        X.append(fastdtw(event,df3[el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_4':\n",
    "                        X.append(fastdtw(event,df4[el[1]:el[2]])[0])\n",
    "                #_________________________________________________\n",
    "                Y.append((from_event,X))\n",
    "        Data_DS[wind].append((label,Y))\n",
    "        #------------------------------------------------------\n",
    "\n",
    "t2=time.time()\n",
    "with open(\"Disstance_new.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Data_DS, fp)\n",
    "\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton distant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Disstance_new.txt\", \"rb\") as fp:\n",
    "    Data_DS = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('curva_direita_agressiva',\n",
       " [('aceleracao_agressiva',\n",
       "   [123.43843946459042,\n",
       "    124.75528366567622,\n",
       "    145.1479214438982,\n",
       "    135.67603087402017,\n",
       "    143.29110616590413,\n",
       "    137.8425245170222,\n",
       "    126.1818426566715,\n",
       "    131.75343986065002,\n",
       "    126.327940264037,\n",
       "    135.1082475335401,\n",
       "    125.70907663022564,\n",
       "    123.61703605099746]),\n",
       "  ('curva_direita_agressiva',\n",
       "   [93.52283989020881,\n",
       "    112.41024691299866,\n",
       "    150.7662537657206,\n",
       "    115.43838881348852,\n",
       "    121.8153769146319,\n",
       "    146.45128927636375,\n",
       "    170.42775001568972,\n",
       "    146.27784005221702,\n",
       "    144.80350186555594,\n",
       "    176.47196135587836,\n",
       "    162.5058629404148]),\n",
       "  ('curva_esquerda_agressiva',\n",
       "   [240.20416198825208,\n",
       "    246.86324371545683,\n",
       "    240.66936509415694,\n",
       "    258.45765779643807,\n",
       "    252.77165521649195,\n",
       "    187.78798599839948,\n",
       "    184.68795127436724,\n",
       "    193.86718011747237,\n",
       "    191.93115148019763,\n",
       "    186.85716148186634,\n",
       "    182.12753757679485])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_DS[226][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataset for labeling\n",
    "TrainData=dict()\n",
    "for win in Data_DS:\n",
    "    x=Data_DS[win]\n",
    "    dumy_list=list()\n",
    "    for events in x:\n",
    "        dumy_dict=dict()\n",
    "        dumy_dict.update({'label':events[0]})\n",
    "        for name , event in events[1]:\n",
    "            for tag,number in enumerate(event):\n",
    "                dumy_dict.update({name+str(tag):number})\n",
    "        dumy_list.append(dumy_dict)\n",
    "    TrainData.update({win:pd.DataFrame(dumy_list)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>aceleracao_agressiva0</th>\n",
       "      <th>aceleracao_agressiva1</th>\n",
       "      <th>aceleracao_agressiva2</th>\n",
       "      <th>aceleracao_agressiva3</th>\n",
       "      <th>aceleracao_agressiva4</th>\n",
       "      <th>aceleracao_agressiva5</th>\n",
       "      <th>aceleracao_agressiva6</th>\n",
       "      <th>aceleracao_agressiva7</th>\n",
       "      <th>aceleracao_agressiva8</th>\n",
       "      <th>...</th>\n",
       "      <th>curva_esquerda_agressiva1</th>\n",
       "      <th>curva_esquerda_agressiva2</th>\n",
       "      <th>curva_esquerda_agressiva3</th>\n",
       "      <th>curva_esquerda_agressiva4</th>\n",
       "      <th>curva_esquerda_agressiva5</th>\n",
       "      <th>curva_esquerda_agressiva6</th>\n",
       "      <th>curva_esquerda_agressiva7</th>\n",
       "      <th>curva_esquerda_agressiva8</th>\n",
       "      <th>curva_esquerda_agressiva9</th>\n",
       "      <th>curva_esquerda_agressiva10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAG</td>\n",
       "      <td>50.733949</td>\n",
       "      <td>45.527406</td>\n",
       "      <td>61.228510</td>\n",
       "      <td>57.905315</td>\n",
       "      <td>67.391861</td>\n",
       "      <td>58.919391</td>\n",
       "      <td>28.009276</td>\n",
       "      <td>38.157511</td>\n",
       "      <td>21.280224</td>\n",
       "      <td>...</td>\n",
       "      <td>175.602936</td>\n",
       "      <td>172.842644</td>\n",
       "      <td>177.853763</td>\n",
       "      <td>169.891504</td>\n",
       "      <td>85.262860</td>\n",
       "      <td>83.767674</td>\n",
       "      <td>107.804784</td>\n",
       "      <td>110.899312</td>\n",
       "      <td>83.877636</td>\n",
       "      <td>82.114295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NAG</td>\n",
       "      <td>55.691722</td>\n",
       "      <td>47.262289</td>\n",
       "      <td>63.211241</td>\n",
       "      <td>54.136382</td>\n",
       "      <td>66.348072</td>\n",
       "      <td>60.928024</td>\n",
       "      <td>29.150635</td>\n",
       "      <td>40.017111</td>\n",
       "      <td>23.634941</td>\n",
       "      <td>...</td>\n",
       "      <td>176.745174</td>\n",
       "      <td>178.083307</td>\n",
       "      <td>175.974270</td>\n",
       "      <td>169.122364</td>\n",
       "      <td>87.633776</td>\n",
       "      <td>88.221394</td>\n",
       "      <td>107.310809</td>\n",
       "      <td>114.707554</td>\n",
       "      <td>87.736039</td>\n",
       "      <td>87.820233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAG</td>\n",
       "      <td>58.873378</td>\n",
       "      <td>54.692960</td>\n",
       "      <td>67.108468</td>\n",
       "      <td>60.967408</td>\n",
       "      <td>65.260639</td>\n",
       "      <td>61.006394</td>\n",
       "      <td>41.209829</td>\n",
       "      <td>49.983163</td>\n",
       "      <td>33.943858</td>\n",
       "      <td>...</td>\n",
       "      <td>186.452239</td>\n",
       "      <td>178.706534</td>\n",
       "      <td>183.372789</td>\n",
       "      <td>174.400253</td>\n",
       "      <td>100.301814</td>\n",
       "      <td>98.700184</td>\n",
       "      <td>116.901029</td>\n",
       "      <td>123.574443</td>\n",
       "      <td>100.491775</td>\n",
       "      <td>98.791633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NAG</td>\n",
       "      <td>62.601043</td>\n",
       "      <td>56.315239</td>\n",
       "      <td>73.168638</td>\n",
       "      <td>55.687224</td>\n",
       "      <td>66.778291</td>\n",
       "      <td>65.032147</td>\n",
       "      <td>44.251642</td>\n",
       "      <td>51.150345</td>\n",
       "      <td>39.161610</td>\n",
       "      <td>...</td>\n",
       "      <td>181.510372</td>\n",
       "      <td>177.156203</td>\n",
       "      <td>188.311824</td>\n",
       "      <td>175.103337</td>\n",
       "      <td>101.433854</td>\n",
       "      <td>97.303773</td>\n",
       "      <td>118.509006</td>\n",
       "      <td>123.978252</td>\n",
       "      <td>100.776132</td>\n",
       "      <td>98.581939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAG</td>\n",
       "      <td>64.006286</td>\n",
       "      <td>64.386101</td>\n",
       "      <td>75.324099</td>\n",
       "      <td>60.262129</td>\n",
       "      <td>70.366699</td>\n",
       "      <td>68.406183</td>\n",
       "      <td>51.413496</td>\n",
       "      <td>61.115567</td>\n",
       "      <td>45.037985</td>\n",
       "      <td>...</td>\n",
       "      <td>187.397818</td>\n",
       "      <td>180.372937</td>\n",
       "      <td>185.788645</td>\n",
       "      <td>170.716829</td>\n",
       "      <td>107.744268</td>\n",
       "      <td>106.070321</td>\n",
       "      <td>123.663580</td>\n",
       "      <td>125.292165</td>\n",
       "      <td>109.540565</td>\n",
       "      <td>106.642978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NAG</td>\n",
       "      <td>72.122338</td>\n",
       "      <td>70.718791</td>\n",
       "      <td>81.031080</td>\n",
       "      <td>64.002540</td>\n",
       "      <td>82.377462</td>\n",
       "      <td>78.173127</td>\n",
       "      <td>55.704609</td>\n",
       "      <td>64.030947</td>\n",
       "      <td>56.257695</td>\n",
       "      <td>...</td>\n",
       "      <td>184.218375</td>\n",
       "      <td>178.661019</td>\n",
       "      <td>182.842637</td>\n",
       "      <td>171.765149</td>\n",
       "      <td>117.178397</td>\n",
       "      <td>112.154796</td>\n",
       "      <td>128.707339</td>\n",
       "      <td>128.165206</td>\n",
       "      <td>114.969047</td>\n",
       "      <td>112.017820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAG</td>\n",
       "      <td>71.415579</td>\n",
       "      <td>66.759312</td>\n",
       "      <td>95.310363</td>\n",
       "      <td>66.660380</td>\n",
       "      <td>75.309186</td>\n",
       "      <td>75.655476</td>\n",
       "      <td>55.317970</td>\n",
       "      <td>63.325326</td>\n",
       "      <td>55.493911</td>\n",
       "      <td>...</td>\n",
       "      <td>183.769874</td>\n",
       "      <td>181.887337</td>\n",
       "      <td>202.894040</td>\n",
       "      <td>189.785885</td>\n",
       "      <td>111.755069</td>\n",
       "      <td>107.030408</td>\n",
       "      <td>128.810032</td>\n",
       "      <td>124.818152</td>\n",
       "      <td>112.686581</td>\n",
       "      <td>107.089351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NAG</td>\n",
       "      <td>73.964603</td>\n",
       "      <td>62.061881</td>\n",
       "      <td>71.953314</td>\n",
       "      <td>65.717418</td>\n",
       "      <td>72.238694</td>\n",
       "      <td>68.645762</td>\n",
       "      <td>51.816904</td>\n",
       "      <td>60.183995</td>\n",
       "      <td>51.545210</td>\n",
       "      <td>...</td>\n",
       "      <td>186.620605</td>\n",
       "      <td>184.783090</td>\n",
       "      <td>193.560253</td>\n",
       "      <td>183.665986</td>\n",
       "      <td>107.274229</td>\n",
       "      <td>108.176175</td>\n",
       "      <td>126.179832</td>\n",
       "      <td>122.194750</td>\n",
       "      <td>107.982390</td>\n",
       "      <td>105.047497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NAG</td>\n",
       "      <td>67.280639</td>\n",
       "      <td>61.111006</td>\n",
       "      <td>86.098367</td>\n",
       "      <td>70.445486</td>\n",
       "      <td>71.408751</td>\n",
       "      <td>75.098119</td>\n",
       "      <td>56.495319</td>\n",
       "      <td>59.890135</td>\n",
       "      <td>52.355220</td>\n",
       "      <td>...</td>\n",
       "      <td>183.649820</td>\n",
       "      <td>174.700108</td>\n",
       "      <td>176.131992</td>\n",
       "      <td>170.703778</td>\n",
       "      <td>110.400651</td>\n",
       "      <td>109.991383</td>\n",
       "      <td>119.716811</td>\n",
       "      <td>126.921129</td>\n",
       "      <td>110.716835</td>\n",
       "      <td>111.525033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>curva_direita_agressiva</td>\n",
       "      <td>70.072598</td>\n",
       "      <td>68.919831</td>\n",
       "      <td>77.954013</td>\n",
       "      <td>73.576495</td>\n",
       "      <td>78.784931</td>\n",
       "      <td>78.357280</td>\n",
       "      <td>62.224084</td>\n",
       "      <td>68.012336</td>\n",
       "      <td>57.669670</td>\n",
       "      <td>...</td>\n",
       "      <td>170.334668</td>\n",
       "      <td>169.953266</td>\n",
       "      <td>191.020530</td>\n",
       "      <td>183.630492</td>\n",
       "      <td>118.029831</td>\n",
       "      <td>113.493390</td>\n",
       "      <td>132.112202</td>\n",
       "      <td>127.986984</td>\n",
       "      <td>117.232858</td>\n",
       "      <td>116.095740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label  aceleracao_agressiva0  aceleracao_agressiva1  \\\n",
       "0                      NAG              50.733949              45.527406   \n",
       "1                      NAG              55.691722              47.262289   \n",
       "2                      NAG              58.873378              54.692960   \n",
       "3                      NAG              62.601043              56.315239   \n",
       "4                      NAG              64.006286              64.386101   \n",
       "5                      NAG              72.122338              70.718791   \n",
       "6                      NAG              71.415579              66.759312   \n",
       "7                      NAG              73.964603              62.061881   \n",
       "8                      NAG              67.280639              61.111006   \n",
       "9  curva_direita_agressiva              70.072598              68.919831   \n",
       "\n",
       "   aceleracao_agressiva2  aceleracao_agressiva3  aceleracao_agressiva4  \\\n",
       "0              61.228510              57.905315              67.391861   \n",
       "1              63.211241              54.136382              66.348072   \n",
       "2              67.108468              60.967408              65.260639   \n",
       "3              73.168638              55.687224              66.778291   \n",
       "4              75.324099              60.262129              70.366699   \n",
       "5              81.031080              64.002540              82.377462   \n",
       "6              95.310363              66.660380              75.309186   \n",
       "7              71.953314              65.717418              72.238694   \n",
       "8              86.098367              70.445486              71.408751   \n",
       "9              77.954013              73.576495              78.784931   \n",
       "\n",
       "   aceleracao_agressiva5  aceleracao_agressiva6  aceleracao_agressiva7  \\\n",
       "0              58.919391              28.009276              38.157511   \n",
       "1              60.928024              29.150635              40.017111   \n",
       "2              61.006394              41.209829              49.983163   \n",
       "3              65.032147              44.251642              51.150345   \n",
       "4              68.406183              51.413496              61.115567   \n",
       "5              78.173127              55.704609              64.030947   \n",
       "6              75.655476              55.317970              63.325326   \n",
       "7              68.645762              51.816904              60.183995   \n",
       "8              75.098119              56.495319              59.890135   \n",
       "9              78.357280              62.224084              68.012336   \n",
       "\n",
       "   aceleracao_agressiva8  ...  curva_esquerda_agressiva1  \\\n",
       "0              21.280224  ...                 175.602936   \n",
       "1              23.634941  ...                 176.745174   \n",
       "2              33.943858  ...                 186.452239   \n",
       "3              39.161610  ...                 181.510372   \n",
       "4              45.037985  ...                 187.397818   \n",
       "5              56.257695  ...                 184.218375   \n",
       "6              55.493911  ...                 183.769874   \n",
       "7              51.545210  ...                 186.620605   \n",
       "8              52.355220  ...                 183.649820   \n",
       "9              57.669670  ...                 170.334668   \n",
       "\n",
       "   curva_esquerda_agressiva2  curva_esquerda_agressiva3  \\\n",
       "0                 172.842644                 177.853763   \n",
       "1                 178.083307                 175.974270   \n",
       "2                 178.706534                 183.372789   \n",
       "3                 177.156203                 188.311824   \n",
       "4                 180.372937                 185.788645   \n",
       "5                 178.661019                 182.842637   \n",
       "6                 181.887337                 202.894040   \n",
       "7                 184.783090                 193.560253   \n",
       "8                 174.700108                 176.131992   \n",
       "9                 169.953266                 191.020530   \n",
       "\n",
       "   curva_esquerda_agressiva4  curva_esquerda_agressiva5  \\\n",
       "0                 169.891504                  85.262860   \n",
       "1                 169.122364                  87.633776   \n",
       "2                 174.400253                 100.301814   \n",
       "3                 175.103337                 101.433854   \n",
       "4                 170.716829                 107.744268   \n",
       "5                 171.765149                 117.178397   \n",
       "6                 189.785885                 111.755069   \n",
       "7                 183.665986                 107.274229   \n",
       "8                 170.703778                 110.400651   \n",
       "9                 183.630492                 118.029831   \n",
       "\n",
       "   curva_esquerda_agressiva6  curva_esquerda_agressiva7  \\\n",
       "0                  83.767674                 107.804784   \n",
       "1                  88.221394                 107.310809   \n",
       "2                  98.700184                 116.901029   \n",
       "3                  97.303773                 118.509006   \n",
       "4                 106.070321                 123.663580   \n",
       "5                 112.154796                 128.707339   \n",
       "6                 107.030408                 128.810032   \n",
       "7                 108.176175                 126.179832   \n",
       "8                 109.991383                 119.716811   \n",
       "9                 113.493390                 132.112202   \n",
       "\n",
       "   curva_esquerda_agressiva8  curva_esquerda_agressiva9  \\\n",
       "0                 110.899312                  83.877636   \n",
       "1                 114.707554                  87.736039   \n",
       "2                 123.574443                 100.491775   \n",
       "3                 123.978252                 100.776132   \n",
       "4                 125.292165                 109.540565   \n",
       "5                 128.165206                 114.969047   \n",
       "6                 124.818152                 112.686581   \n",
       "7                 122.194750                 107.982390   \n",
       "8                 126.921129                 110.716835   \n",
       "9                 127.986984                 117.232858   \n",
       "\n",
       "   curva_esquerda_agressiva10  \n",
       "0                   82.114295  \n",
       "1                   87.820233  \n",
       "2                   98.791633  \n",
       "3                   98.581939  \n",
       "4                  106.642978  \n",
       "5                  112.017820  \n",
       "6                  107.089351  \n",
       "7                  105.047497  \n",
       "8                  111.525033  \n",
       "9                  116.095740  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData[226].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize Train Data\n",
    "#Balance it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  300.0  %  is complete\n",
      "395 min has time for calculaton Model\n"
     ]
    }
   ],
   "source": [
    "#dont run this part\n",
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "t1=time.time()\n",
    "n,k=0,12*50\n",
    "\n",
    "Result={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wid in Result:\n",
    "    data=TrainData[wid].drop('label',1)\n",
    "    label=TrainData[wid].label\n",
    "    #\n",
    "    for Max_depth in range(1,13):\n",
    "        estimator = Id3Estimator(max_depth=Max_depth, min_samples_split=1, prune=True,\n",
    "                        gain_ratio=True, min_entropy_decrease=0, is_repeating=True)\n",
    "        #run it in itaraion for the best trees\n",
    "        NUMBER_OF_TEST=50\n",
    "        temp=list()\n",
    "        for NT in range(NUMBER_OF_TEST):\n",
    "            clear_output(wait=True)\n",
    "            n=n+1\n",
    "            print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "            estimator.fit(data,label , check_input=True)\n",
    "            ACC=accuracy_score(y_true=label,y_pred=estimator.predict(data))\n",
    "            temp.append((ACC,deepcopy(estimator)))\n",
    "        temp_index=[(x[0],i) for i,x in enumerate(temp)]\n",
    "        temp_index.sort()\n",
    "        Acc=temp[temp_index[-1][1]][0]\n",
    "        estimator=temp[temp_index[-1][1]][1]\n",
    "        Result[wid].append((Acc,deepcopy(estimator)))\n",
    "\n",
    "with open(\"Model_new_1.txt\", \"wb\") as fp:\n",
    "    pickle.dump(Result, fp)\n",
    "t2=time.time()\n",
    "print(round((t2-t1)/60) ,'min has time for calculaton Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator, export_text\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "with open(\"Model_new_1.txt\", \"rb\") as fp:\n",
    "    Result = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926346801346801\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                           NAG       0.99      1.00      1.00      4682\n",
      " troca_faixa_direita_agressiva       0.93      0.46      0.62        28\n",
      "troca_faixa_esquerda_agressiva       0.92      0.57      0.71        42\n",
      "\n",
      "                      accuracy                           0.99      4752\n",
      "                     macro avg       0.95      0.68      0.77      4752\n",
      "                  weighted avg       0.99      0.99      0.99      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=9\n",
    "wid=126\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888047415212381\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "             NAG       0.99      1.00      0.99      2979\n",
      "freada_agressiva       0.96      0.43      0.60        58\n",
      "\n",
      "        accuracy                           0.99      3037\n",
      "       macro avg       0.98      0.72      0.79      3037\n",
      "    weighted avg       0.99      0.99      0.99      3037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=9\n",
    "wid=186\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9453340695748206\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                     NAG       0.94      1.00      0.97      3223\n",
      "    aceleracao_agressiva       0.92      0.12      0.22        89\n",
      " curva_direita_agressiva       0.96      0.62      0.75       157\n",
      "curva_esquerda_agressiva       0.95      0.67      0.78       153\n",
      "\n",
      "                accuracy                           0.95      3622\n",
      "               macro avg       0.94      0.60      0.68      3622\n",
      "            weighted avg       0.95      0.95      0.93      3622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Max_depth=8\n",
    "wid=226\n",
    "\n",
    "label=TrainData[wid].label\n",
    "data=TrainData[wid].drop('label',1)\n",
    "\n",
    "Acc=Result[wid][Max_depth-1][0]\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "print(Acc)\n",
    "print(classification_report(label, estimator.predict(data)))\n",
    "#print(export_text(estimator.tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overfit model!\n",
    "Overfit_model={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wid in Overfit_model:\n",
    "    data=TrainData[wid].drop('label',1)\n",
    "    label=TrainData[wid].label\n",
    "    #\n",
    "    estimator = Id3Estimator(max_depth=400, min_samples_split=1, prune=False,\n",
    "                    gain_ratio=True, min_entropy_decrease=0, is_repeating=True)\n",
    "    #run it in itaraion for the best trees\n",
    "    NUMBER_OF_TEST=10\n",
    "    temp=list()\n",
    "    for NT in range(NUMBER_OF_TEST):\n",
    "        estimator.fit(data,label , check_input=True)\n",
    "        ACC=accuracy_score(y_true=label,y_pred=estimator.predict(data))\n",
    "        temp.append((ACC,deepcopy(estimator)))\n",
    "    temp_index=[(x[0],i) for i,x in enumerate(temp)]\n",
    "    temp_index.sort()\n",
    "    Acc=temp[temp_index[-1][1]][0]\n",
    "    estimator=temp[temp_index[-1][1]][1]\n",
    "    Overfit_model[wid]=(Acc,deepcopy(estimator))\n",
    "\n",
    "with open(\"TrainData_test_l_1.txt\", \"wb\") as fp:\n",
    "    pickle.dump((Overfit_model), fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                     NAG       1.00      1.00      1.00      3223\n",
      "    aceleracao_agressiva       1.00      1.00      1.00        89\n",
      " curva_direita_agressiva       1.00      1.00      1.00       157\n",
      "curva_esquerda_agressiva       1.00      1.00      1.00       153\n",
      "\n",
      "                accuracy                           1.00      3622\n",
      "               macro avg       1.00      1.00      1.00      3622\n",
      "            weighted avg       1.00      1.00      1.00      3622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wid=226\n",
    "data=TrainData[wid].drop('label',1)\n",
    "label=TrainData[wid].label\n",
    "print(classification_report(label, Overfit_model[wid][1].predict(data)))\n",
    "#its completely ovefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swich to thease data set for finding labels\n",
    "with open(\"Data/data_list_per_driver\", \"rb\") as fp:\n",
    "        Sensory_data = pickle.load(fp)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disstance calculatoin  100.0  %  is complete\n",
      "448 min has time left\n"
     ]
    }
   ],
   "source": [
    "Lambda=1\n",
    "sample_rate=1#0.04/0.02\n",
    "t1=time.time()\n",
    "def TempEvent_genarator_new(Lambda,df,L,i):\n",
    "    M=int((L)*Lambda)\n",
    "    temp_event=list()\n",
    "    pointer=0\n",
    "    stop=False\n",
    "    #go on timeserise for event extraction\n",
    "    while stop!=True:\n",
    "        clear_output(wait=True)\n",
    "        pointer=pointer + M\n",
    "        l_min=pointer-int(L/2)\n",
    "        l_max=pointer+int(L/2)\n",
    "        if l_max<0:\n",
    "            l_max=L/2\n",
    "        if (l_min<0):\n",
    "            l_min=0\n",
    "        if (l_max>len(df)):\n",
    "            l_max=len(df)\n",
    "            stop=True\n",
    "        print('extraction ',l_max/len(df),' % of ',i,' is complete')\n",
    "        temp_event.append(df[l_min:l_max])\n",
    "    return temp_event\n",
    "\n",
    "temp_event_test_new=list()\n",
    "for l,DF in enumerate(Sensory_data):\n",
    "    te=list()\n",
    "    for i,lw in enumerate(window):\n",
    "        te.append(TempEvent_genarator_new(Lambda,DF,lw/sample_rate,i+1))\n",
    "    temp_event_test_new.append(te)\n",
    "\n",
    "#make it dataframe\n",
    "Data_test_new={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "for driver in range(len(temp_event_test_new)):\n",
    "    Data_test_new[226]=Data_test_new[226]+[ x for x in temp_event_test_new[driver][0] ]\n",
    "    Data_test_new[186]=Data_test_new[186]+[ x for x in temp_event_test_new[driver][1] ]\n",
    "    Data_test_new[126]=Data_test_new[126]+[ x for x in temp_event_test_new[driver][2] ]\n",
    "    \n",
    "    \n",
    "#calculate distance\n",
    "k,n=0,0\n",
    "num_event=dict(evented_label_All.groupby(0).size())\n",
    "for lenght in window:\n",
    "    for name in window[lenght]:\n",
    "        k=k+len(Data_test_new[lenght])*num_event[name]\n",
    "\n",
    "Data_DS_test_new={\n",
    "      226:[],\n",
    "      126:[],\n",
    "      186:[],\n",
    "       }\n",
    "\n",
    "for wind in Data_test_new:\n",
    "    for event in Data_test_new[wind]:\n",
    "         #---------for each Data-distance from events----------\n",
    "        Y=list()\n",
    "        for from_event,dfe in evented_label_All.groupby(0):\n",
    "            if from_event in window[wind]:\n",
    "                X=list()\n",
    "                #____for each event_distance from each label_____\n",
    "                for el in dfe.iloc:\n",
    "                    clear_output(wait=True)\n",
    "                    n=n+1\n",
    "                    print('disstance calculatoin ',round((n/k)*100,4),' %  is complete')\n",
    "                    if   el[3]=='evented_label_1':\n",
    "                        X.append(fastdtw(event,df1[el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_2':\n",
    "                        X.append(fastdtw(event,df2[el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_3':\n",
    "                        X.append(fastdtw(event,df3[el[1]:el[2]])[0])\n",
    "                    elif el[3]=='evented_label_4':\n",
    "                        X.append(fastdtw(event,df4[el[1]:el[2]])[0])\n",
    "                #_________________________________________________\n",
    "                Y.append((from_event,X))\n",
    "        Data_DS_test_new[wind].append(Y)\n",
    "        #------------------------------------------------------\n",
    "#prepare dataset for labeling\n",
    "Test_new=dict()\n",
    "for win in Data_DS_test_new:\n",
    "    dumy_list=list()\n",
    "    for events in Data_DS_test_new[win]:\n",
    "        dumy_dict=dict()\n",
    "        for name , event in events:\n",
    "            for tag,number in enumerate(event):\n",
    "                dumy_dict.update({name+str(tag):number})\n",
    "        dumy_list.append(dumy_dict)\n",
    "    Test_new.update({win:pd.DataFrame(dumy_list)})\n",
    "t2=time.time()\n",
    "print(round((t2-t1)/60) ,'min has time left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAG'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max_depth=8\n",
    "wid=226\n",
    "\n",
    "estimator=Result[wid][Max_depth-1][1]\n",
    "{x for x in estimator.predict(Test_new[wid])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in wid window:\n",
    "    estimator=Result[wid][5][1]\n",
    "    x={x for x in estimator.predict(Test_new[wid])}\n",
    "    print(f\" {wid} is : {x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "x=data.columns[30]\n",
    "rep=re.compile(r'(\\w+)(\\d+)')\n",
    "mo=rep.findall(x)[0]\n",
    "print(mo[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot charts for find the optimom\n",
    "Y1=[x[0]for x in Result[226]]\n",
    "Y2=[x[0]for x in Result[186]]\n",
    "Y3=[x[0]for x in Result[126]]\n",
    "\n",
    "X=range(1,11)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(X,Y1, linestyle='-', linewidth=2,c='r')\n",
    "ax.plot(X,Y2, linestyle='-', linewidth=2,c='g')\n",
    "ax.plot(X,Y3, linestyle='-', linewidth=2,c='b')\n",
    "\n",
    "ax.legend();\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
